"""æŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆ Markdown å’Œ HTML æ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from jinja2 import Environment, FileSystemLoader, select_autoescape
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from loguru import logger


@dataclass
class ReportData:
    """æŠ¥å‘Šæ•°æ®"""
    title: str
    generated_at: datetime
    config: Dict[str, Any]
    results: List[Dict[str, Any]]
    summary: Dict[str, Any]


class ReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, template_dir: Optional[str] = None):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®æ¨¡æ¿
        """
        if template_dir is None:
            template_dir = Path(__file__).parent / "templates"

        self.template_dir = Path(template_dir)
        self.env = Environment(
            loader=FileSystemLoader(str(self.template_dir)),
            autoescape=select_autoescape(['html', 'xml'])
        )

    def generate_report(
        self,
        results: List[Dict[str, Any]],
        config: Dict[str, Any],
        output_dir: str,
        formats: List[str] = ["markdown", "html"]
    ) -> Dict[str, str]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š

        Args:
            results: æµ‹è¯•ç»“æœåˆ—è¡¨
            config: æµ‹è¯•é…ç½®
            output_dir: è¾“å‡ºç›®å½•
            formats: è¾“å‡ºæ ¼å¼åˆ—è¡¨

        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # åˆ†ç±»ç»“æœ
        kb_results = [r for r in results if r.get("adapter_type") == "knowledge_base"]
        memory_results = [r for r in results if r.get("adapter_type") == "memory"]

        generated_files = {}
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # ç”ŸæˆçŸ¥è¯†åº“æŠ¥å‘Š
        if kb_results:
            report_data = self._prepare_report_data(kb_results, config, "knowledge_base")

            if "markdown" in formats:
                md_path = output_path / f"kb_report_{timestamp}.md"
                self._generate_markdown(report_data, md_path)
                generated_files["kb_markdown"] = str(md_path)
                logger.info(f"ç”ŸæˆçŸ¥è¯†åº“ Markdown æŠ¥å‘Š: {md_path}")

            if "html" in formats:
                html_path = output_path / f"kb_report_{timestamp}.html"
                self._generate_html(report_data, html_path)
                generated_files["kb_html"] = str(html_path)
                logger.info(f"ç”ŸæˆçŸ¥è¯†åº“ HTML æŠ¥å‘Š: {html_path}")

        # ç”Ÿæˆè®°å¿†ç³»ç»ŸæŠ¥å‘Š
        if memory_results:
            report_data = self._prepare_report_data(memory_results, config, "memory")

            if "markdown" in formats:
                md_path = output_path / f"memory_report_{timestamp}.md"
                self._generate_markdown(report_data, md_path)
                generated_files["memory_markdown"] = str(md_path)
                logger.info(f"ç”Ÿæˆè®°å¿†ç³»ç»Ÿ Markdown æŠ¥å‘Š: {md_path}")

            if "html" in formats:
                html_path = output_path / f"memory_report_{timestamp}.html"
                self._generate_html(report_data, html_path)
                generated_files["memory_html"] = str(html_path)
                logger.info(f"ç”Ÿæˆè®°å¿†ç³»ç»Ÿ HTML æŠ¥å‘Š: {html_path}")

        # è‡ªåŠ¨åŒæ­¥åˆ° web/reports ç›®å½•ï¼ˆç”¨äº Railway éƒ¨ç½²ï¼‰
        self._sync_to_web_reports(generated_files)

        return generated_files

    def _prepare_report_data(
        self,
        results: List[Dict[str, Any]],
        config: Dict[str, Any],
        report_type: str = "knowledge_base"
    ) -> ReportData:
        """å‡†å¤‡æŠ¥å‘Šæ•°æ®
        
        Args:
            results: æµ‹è¯•ç»“æœåˆ—è¡¨ï¼ˆå·²è¿‡æ»¤ä¸ºå•ä¸€ç±»å‹ï¼‰
            config: æµ‹è¯•é…ç½®
            report_type: æŠ¥å‘Šç±»å‹ ("knowledge_base" æˆ– "memory")
        """
        # è®¡ç®—æ•°æ®è§„æ¨¡ä¿¡æ¯
        if report_type == "knowledge_base":
            doc_count = 100  # çŸ¥è¯†åº“æµ‹è¯•æŠ¥å‘Šä¸­æ–‡æ¡£æ•°ç»Ÿä¸€ä¸º 100
            if results and results[0].get('details'):
                doc_count = results[0]['details'].get('doc_count', 100)
            title = "äº‘ç«¯çŸ¥è¯†åº“æ€§èƒ½æµ‹è¯•æŠ¥å‘Š"
        else:
            # è®°å¿†ç³»ç»Ÿï¼šè®¡ç®—è®°å¿†æ¡ç›®æ•°
            memory_count = 100  # é»˜è®¤å€¼
            user_count = 10  # é»˜è®¤ç”¨æˆ·æ•°
            query_count = 5  # é»˜è®¤æŸ¥è¯¢æ•°
            if results and results[0].get('details'):
                memory_count = results[0]['details'].get('memory_count', 100)
                user_count = results[0]['details'].get('user_count', 10)
                query_count = results[0]['details'].get('query_count', 5)
            title = "äº‘ç«¯è®°å¿†ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"
            doc_count = memory_count  # ç”¨äºç»Ÿä¸€æ¥å£

        # è®¡ç®—æ±‡æ€»
        summary = {
            "total_tests": len(results),
            "data_scales": list(set(r.get("data_scale", "unknown") for r in results)),
            "adapters_tested": list(set(r.get("adapter_name", "unknown") for r in results)),
            "doc_count": doc_count,
            "report_type": report_type,
        }

        if report_type == "memory":
            summary["memory_count"] = doc_count
            summary["user_count"] = user_count
            summary["query_count"] = query_count

        # ç»“æœæ±‡æ€»
        summary["results_summary"] = self._summarize_results(results)

        return ReportData(
            title=title,
            generated_at=datetime.now(),
            config=config,
            results=results,
            summary=summary
        )

    def _summarize_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ±‡æ€»æµ‹è¯•ç»“æœ"""
        if not results:
            return {}

        latencies = []
        throughputs = []

        for r in results:
            if r.get("latency"):
                latencies.append(r["latency"])
            if r.get("throughput"):
                throughputs.append(r["throughput"])

        summary = {
            "count": len(results),
            "adapters": [r.get("adapter_name") for r in results],
        }

        if latencies:
            summary["avg_p50_latency"] = sum(l.get("p50_ms", 0) for l in latencies) / len(latencies)
            summary["avg_p95_latency"] = sum(l.get("p95_ms", 0) for l in latencies) / len(latencies)

        if throughputs:
            summary["avg_qps"] = sum(t.get("qps", 0) for t in throughputs) / len(throughputs)

        return summary

    def _generate_markdown(self, data: ReportData, output_path: Path):
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        report_type = data.summary.get("report_type", "knowledge_base")
        
        if report_type == "knowledge_base":
            self._generate_kb_markdown(data, output_path)
        else:
            self._generate_memory_markdown(data, output_path)
    
    def _generate_kb_markdown(self, data: ReportData, output_path: Path):
        """ç”ŸæˆçŸ¥è¯†åº“ Markdown æŠ¥å‘Š"""
        lines = []
        kb_results = data.results
        doc_count = data.summary.get("doc_count", 100)

        # æ ‡é¢˜
        lines.append(f"# {data.title}")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {data.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # ä¸€ã€å‚ä¸å¯¹æ¯”çš„å››ä¸ªçŸ¥è¯†åº“ + æ¶æ„å¯¹æ¯”
        lines.append("## ä¸€ã€å‚ä¸å¯¹æ¯”çš„çŸ¥è¯†åº“")
        lines.append("")
        lines.extend(self._generate_kb_intro(kb_results))
        if kb_results and len(kb_results) >= 2:
            lines.append("### ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹å¯¹æ¯”")
            lines.append("")
            lines.extend(self._generate_architecture_comparison(kb_results))
        lines.append("")

        # äºŒã€æµ‹è¯•æ–¹æ³•ï¼ˆå·²é¢„å…ˆå…¥åº“ 100 ä¸ªæ–‡æ¡£ï¼‰
        lines.append("## äºŒã€æµ‹è¯•æ–¹æ³•")
        lines.append("")
        lines.extend(self._generate_test_methodology(data))
        lines.append("")

        # ä¸‰ã€å¯¹æ¯”ç»“æœï¼šæ—¶å»¶ã€ååã€æ£€ç´¢è´¨é‡ã€æˆæœ¬ï¼ˆè¡¨æ ¼ï¼‰+ ç»¼åˆå¯¹æ¯”
        lines.append("## ä¸‰ã€å¯¹æ¯”ç»“æœ")
        lines.append("")
        if kb_results:
            lines.append("### æ—¶å»¶å¯¹æ¯”")
            lines.append("")
            lines.append("| çŸ¥è¯†åº“ | P50 (ms) | P95 (ms) | P99 (ms) | å¹³å‡ (ms) |")
            lines.append("|--------|----------|----------|----------|-----------|")
            for r in kb_results:
                lat = r.get("latency", {})
                name = r.get("adapter_name", "-")
                lines.append(f"| {name} | {lat.get('p50_ms', 0):.2f} | {lat.get('p95_ms', 0):.2f} | {lat.get('p99_ms', 0):.2f} | {lat.get('mean_ms', 0):.2f} |")
            lines.append("")

            lines.append("### ååå¯¹æ¯”")
            lines.append("")
            lines.append("| çŸ¥è¯†åº“ | QPS | æ€»è¯·æ±‚æ•° | æˆåŠŸç‡ |")
            lines.append("|--------|-----|----------|--------|")
            for r in kb_results:
                tp = r.get("throughput", {})
                name = r.get("adapter_name", "-")
                succ = 100 - tp.get("error_rate", 0) if tp else 100
                lines.append(f"| {name} | {tp.get('qps', 0):.2f} | {tp.get('total_requests', 0)} | {succ:.1f}% |")
            lines.append("")

            lines.append("### æ£€ç´¢è´¨é‡å¯¹æ¯”")
            lines.append("")
            lines.append("| çŸ¥è¯†åº“ | Precision@1 | MRR | NDCG@10 |")
            lines.append("|--------|-------------|-----|---------|")
            for r in kb_results:
                qual = r.get("quality", {})
                name = r.get("adapter_name", "-")
                lines.append(f"| {name} | {qual.get('precision@1', 0):.3f} | {qual.get('mrr', 0):.3f} | {qual.get('ndcg@10', 0):.3f} |")
            lines.append("")

            lines.append("### æˆæœ¬å¯¹æ¯”ï¼ˆ100 æ–‡æ¡£è§„æ¨¡ä¼°ç®—ï¼‰")
            lines.append("")
            lines.extend(self._generate_cost_table_only(kb_results))
            lines.append("")

            lines.append("### ç»¼åˆå¯¹æ¯”")
            lines.append("")
            lines.extend(self._format_results_table(kb_results, "knowledge_base"))
            lines.extend(self._generate_comprehensive_kb_comparison(kb_results))
            lines.append("")

        # å››ã€é€‰å‹å»ºè®®ï¼ˆä»€ä¹ˆæƒ…å†µä¸‹é€‰æ‹©å“ªä¸ªçŸ¥è¯†åº“ï¼‰
        lines.append("## å››ã€é€‰å‹å»ºè®®")
        lines.append("")
        lines.extend(self._generate_selection_recommendation(kb_results))
        lines.append("")

        # é¡µè„š
        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æŠ¥å‘Šç”±äº‘ç«¯çŸ¥è¯†åº“æ€§èƒ½æµ‹è¯•æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ*")

        output_path.write_text("\n".join(lines), encoding="utf-8")
    
    def _generate_memory_markdown(self, data: ReportData, output_path: Path):
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿ Markdown æŠ¥å‘Š"""
        lines = []
        memory_results = data.results
        memory_count = data.summary.get("memory_count", 100)
        user_count = data.summary.get("user_count", 10)

        # æ ‡é¢˜
        lines.append(f"# {data.title}")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {data.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # ä¸€ã€å‚ä¸å¯¹æ¯”çš„è®°å¿†ç³»ç»Ÿ
        lines.append("## ä¸€ã€å‚ä¸å¯¹æ¯”çš„è®°å¿†ç³»ç»Ÿ")
        lines.append("")
        lines.extend(self._generate_memory_intro(memory_results))
        if memory_results and len(memory_results) >= 2:
            lines.append("### ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹å¯¹æ¯”")
            lines.append("")
            lines.extend(self._generate_memory_architecture_comparison(memory_results))
        lines.append("")

        # äºŒã€æµ‹è¯•æ–¹æ³•
        lines.append("## äºŒã€æµ‹è¯•æ–¹æ³•")
        lines.append("")
        lines.extend(self._generate_memory_test_methodology(data))
        lines.append("")

        # ä¸‰ã€å¯¹æ¯”ç»“æœï¼šæ—¶å»¶ã€ååã€æˆåŠŸç‡
        lines.append("## ä¸‰ã€å¯¹æ¯”ç»“æœ")
        lines.append("")
        if memory_results:
            lines.append("### æ—¶å»¶å¯¹æ¯”")
            lines.append("")
            lines.append("| è®°å¿†ç³»ç»Ÿ | è¿è¡Œæ¨¡å¼ | P50 (ms) | P95 (ms) | P99 (ms) | å¹³å‡ (ms) |")
            lines.append("|----------|----------|----------|----------|----------|-----------|")
            for r in memory_results:
                lat = r.get("latency", {})
                name = r.get("adapter_name", "-")
                run_mode = r.get("details", {}).get("run_mode", "unknown")
                lines.append(f"| {name} | {self._run_mode_label(run_mode)} | {lat.get('p50_ms', 0):.2f} | {lat.get('p95_ms', 0):.2f} | {lat.get('p99_ms', 0):.2f} | {lat.get('mean_ms', 0):.2f} |")
            lines.append("")

            lines.append("### ååå¯¹æ¯”")
            lines.append("")
            lines.append("| è®°å¿†ç³»ç»Ÿ | QPS | æ€»è¯·æ±‚æ•° | æˆåŠŸç‡ |")
            lines.append("|----------|-----|----------|--------|")
            for r in memory_results:
                tp = r.get("throughput", {})
                name = r.get("adapter_name", "-")
                succ = 100 - tp.get("error_rate", 0) if tp else 100
                lines.append(f"| {name} | {tp.get('qps', 0):.2f} | {tp.get('total_requests', 0)} | {succ:.1f}% |")
            lines.append("")

            lines.append("### æˆæœ¬å¯¹æ¯”ï¼ˆä¼°ç®—ï¼‰")
            lines.append("")
            lines.extend(self._generate_memory_cost_table(memory_results))
            lines.append("")

            lines.append("### ç»¼åˆå¯¹æ¯”")
            lines.append("")
            lines.extend(self._format_results_table(memory_results, "memory"))
            lines.extend(self._generate_comprehensive_memory_comparison(memory_results))
            lines.append("")

        # å››ã€é€‰å‹å»ºè®®
        lines.append("## å››ã€é€‰å‹å»ºè®®")
        lines.append("")
        lines.extend(self._generate_memory_selection_recommendation(memory_results))
        lines.append("")

        # é¡µè„š
        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æŠ¥å‘Šç”±äº‘ç«¯è®°å¿†ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ*")

        output_path.write_text("\n".join(lines), encoding="utf-8")

    def _format_results_table(self, results: List[Dict], result_type: str) -> List[str]:
        """æ ¼å¼åŒ–ç»“æœè¡¨æ ¼"""
        lines = []

        if result_type == "knowledge_base":
            lines.append("| çŸ¥è¯†åº“ | P50å»¶è¿Ÿ | P95å»¶è¿Ÿ | QPS | P@1 | MRR | NDCG@10 |")
            lines.append("|--------|---------|---------|-----|-----|-----|---------|")

            for r in results:
                adapter = r.get("adapter_name", "-")
                lat = r.get("latency", {})
                tp = r.get("throughput", {})
                qual = r.get("quality", {})

                p50 = f"{lat.get('p50_ms', 0):.2f}ms" if lat else "-"
                p95 = f"{lat.get('p95_ms', 0):.2f}ms" if lat else "-"
                qps = f"{tp.get('qps', 0):.2f}" if tp else "-"
                p1 = f"{qual.get('precision@1', 0):.3f}" if qual else "-"
                mrr = f"{qual.get('mrr', 0):.3f}" if qual else "-"
                ndcg = f"{qual.get('ndcg@10', 0):.3f}" if qual else "-"

                lines.append(f"| {adapter} | {p50} | {p95} | {qps} | {p1} | {mrr} | {ndcg} |")

        elif result_type == "memory":
            lines.append("| é€‚é…å™¨ | P50å»¶è¿Ÿ | P95å»¶è¿Ÿ | QPS | æˆåŠŸç‡ |")
            lines.append("|--------|---------|---------|-----|--------|")

            for r in results:
                adapter = r.get("adapter_name", "-")
                lat = r.get("latency", {})
                tp = r.get("throughput", {})

                p50 = f"{lat.get('p50_ms', 0):.2f}ms" if lat else "-"
                p95 = f"{lat.get('p95_ms', 0):.2f}ms" if lat else "-"
                qps = f"{tp.get('qps', 0):.1f}" if tp else "-"
                success = f"{100 - tp.get('error_rate', 0):.1f}%" if tp else "-"

                lines.append(f"| {adapter} | {p50} | {p95} | {qps} | {success} |")

        return lines

    def _generate_html(self, data: ReportData, output_path: Path):
        """ç”Ÿæˆ HTML æŠ¥å‘Šï¼ˆå«å›¾è¡¨ï¼‰"""
        # ç”Ÿæˆå®Œæ•´çš„HTMLå†…å®¹éƒ¨åˆ†
        content_html = self._generate_html_content(data)

        # ç”Ÿæˆå›¾è¡¨
        charts = self._generate_charts(data)

        # HTML æ¨¡æ¿
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{data.title}</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
            padding: 20px;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
            margin-bottom: 30px;
        }}
        h2 {{
            color: #34495e;
            margin: 30px 0 20px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
        }}
        h3 {{
            color: #7f8c8d;
            margin: 20px 0 15px;
        }}
        .meta {{
            color: #7f8c8d;
            font-size: 14px;
            margin-bottom: 30px;
        }}
        .summary-cards {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }}
        .card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
        }}
        .card.kb {{
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        }}
        .card.memory {{
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }}
        .card-value {{
            font-size: 36px;
            font-weight: bold;
        }}
        .card-label {{
            font-size: 14px;
            opacity: 0.9;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        th, td {{
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        th {{
            background: #f8f9fa;
            font-weight: 600;
            color: #2c3e50;
        }}
        tr:hover {{
            background: #f8f9fa;
        }}
        .chart-container {{
            margin: 30px 0;
            padding: 20px;
            background: #fafafa;
            border-radius: 8px;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #eee;
            color: #7f8c8d;
            font-size: 12px;
            text-align: center;
        }}
        .badge {{
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: 500;
        }}
        .badge-success {{
            background: #d4edda;
            color: #155724;
        }}
        .badge-info {{
            background: #d1ecf1;
            color: #0c5460;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{data.title}</h1>
        <div class="meta">
            ç”Ÿæˆæ—¶é—´: {data.generated_at.strftime('%Y-%m-%d %H:%M:%S')} |
            è¿è¡Œæ¨¡å¼: <span class="badge badge-info">{data.config.get('mode', 'unknown')}</span> |
            æ•°æ®è§„æ¨¡: <span class="badge badge-info">{data.config.get('scale', 'unknown')}</span>
        </div>

        <h2>æµ‹è¯•æ¦‚è§ˆ</h2>
        <div class="summary-cards">
            <div class="card">
                <div class="card-value">{data.summary['total_tests']}</div>
                <div class="card-label">æ€»æµ‹è¯•æ•°</div>
            </div>
            <div class="card kb">
                <div class="card-value">{len(data.summary['adapters_tested'])}</div>
                <div class="card-label">é€‚é…å™¨æ•°é‡</div>
            </div>
            <div class="card kb">
                <div class="card-value">{data.summary.get('doc_count', data.summary.get('memory_count', 0))}</div>
                <div class="card-label">{'æ–‡æ¡£æ•°é‡' if data.summary.get('report_type') == 'knowledge_base' else 'è®°å¿†æ•°é‡'}</div>
            </div>
        </div>

        {content_html}

        <div class="footer">
            æœ¬æŠ¥å‘Šç”±äº‘ç«¯çŸ¥è¯†åº“æ€§èƒ½æµ‹è¯•æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ
        </div>
    </div>
</body>
</html>
"""
        output_path.write_text(html_content, encoding="utf-8")

    def _generate_results_section(self, data: ReportData) -> str:
        """ç”Ÿæˆç»“æœè¡¨æ ¼ HTML"""
        html = ""

        kb_results = [r for r in data.results if r.get("adapter_type") == "knowledge_base"]
        if kb_results:
            html += "<h2>çŸ¥è¯†åº“æµ‹è¯•ç»“æœ</h2>"
            html += "<table>"
            html += "<tr><th>é€‚é…å™¨</th><th>æ–‡æ¡£æ•°é‡</th><th>P50å»¶è¿Ÿ</th><th>P95å»¶è¿Ÿ</th><th>QPS</th><th>P@1</th><th>MRR</th></tr>"
            for r in kb_results:
                lat = r.get("latency", {})
                tp = r.get("throughput", {})
                qual = r.get("quality", {})
                details = r.get("details", {})
                doc_count = details.get("doc_count", 100)
                p1_val = f"{qual.get('precision@1', 0):.3f}" if qual else "-"
                mrr_val = f"{qual.get('mrr', 0):.3f}" if qual else "-"
                html += f"""<tr>
                    <td>{r.get('adapter_name', '-')}</td>
                    <td>{doc_count} ä¸ª</td>
                    <td>{lat.get('p50_ms', 0):.2f}ms</td>
                    <td>{lat.get('p95_ms', 0):.2f}ms</td>
                    <td>{tp.get('qps', 0):.1f}</td>
                    <td>{p1_val}</td>
                    <td>{mrr_val}</td>
                </tr>"""
            html += "</table>"

        memory_results = [r for r in data.results if r.get("adapter_type") == "memory"]
        if memory_results:
            html += "<h2>æµ‹è¯•ç»“æœ</h2>"
            html += "<table>"
            html += "<tr><th>é€‚é…å™¨</th><th>æ–‡æ¡£æ•°é‡</th><th>P50å»¶è¿Ÿ</th><th>P95å»¶è¿Ÿ</th><th>QPS</th><th>æˆåŠŸç‡</th></tr>"
            for r in memory_results:
                lat = r.get("latency", {})
                tp = r.get("throughput", {})
                details = r.get("details", {})
                memory_count = details.get("memory_count", 20)
                html += f"""<tr>
                    <td>{r.get('adapter_name', '-')}</td>
                    <td>{memory_count} ä¸ª</td>
                    <td>{lat.get('p50_ms', 0):.2f}ms</td>
                    <td>{lat.get('p95_ms', 0):.2f}ms</td>
                    <td>{tp.get('qps', 0):.1f}</td>
                    <td>{100 - tp.get('error_rate', 0):.1f}%</td>
                </tr>"""
            html += "</table>"

        return html

    def _generate_charts(self, data: ReportData) -> str:
        """ç”Ÿæˆå›¾è¡¨ HTML"""
        charts_html = ""

        # å»¶è¿Ÿå¯¹æ¯”å›¾
        adapters = []
        p50_values = []
        p95_values = []
        p99_values = []

        for r in data.results:
            if r.get("latency"):
                adapters.append(r.get("adapter_name", "Unknown"))
                lat = r["latency"]
                p50_values.append(lat.get("p50_ms", 0))
                p95_values.append(lat.get("p95_ms", 0))
                p99_values.append(lat.get("p99_ms", 0))

        if adapters:
            fig = go.Figure()
            fig.add_trace(go.Bar(name='P50', x=adapters, y=p50_values, marker_color='#3498db'))
            fig.add_trace(go.Bar(name='P95', x=adapters, y=p95_values, marker_color='#e74c3c'))
            fig.add_trace(go.Bar(name='P99', x=adapters, y=p99_values, marker_color='#9b59b6'))

            fig.update_layout(
                title='å»¶è¿Ÿå¯¹æ¯” (ms)',
                barmode='group',
                xaxis_title='é€‚é…å™¨',
                yaxis_title='å»¶è¿Ÿ (ms)',
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )

            charts_html += f'<div class="chart-container"><div id="latency-chart"></div></div>'
            charts_html += f'<script>Plotly.newPlot("latency-chart", {fig.to_json()});</script>'

        # ååé‡å¯¹æ¯”å›¾
        adapters = []
        qps_values = []

        for r in data.results:
            if r.get("throughput"):
                adapters.append(r.get("adapter_name", "Unknown"))
                qps_values.append(r["throughput"].get("qps", 0))

        if adapters:
            fig = go.Figure(data=[
                go.Bar(x=adapters, y=qps_values, marker_color='#2ecc71')
            ])

            fig.update_layout(
                title='ååé‡å¯¹æ¯” (QPS)',
                xaxis_title='é€‚é…å™¨',
                yaxis_title='QPS'
            )

            charts_html += f'<div class="chart-container"><div id="throughput-chart"></div></div>'
            charts_html += f'<script>Plotly.newPlot("throughput-chart", {fig.to_json()});</script>'

        # è´¨é‡æŒ‡æ ‡å¯¹æ¯”å›¾ï¼ˆä»…çŸ¥è¯†åº“ï¼‰
        kb_results = [r for r in data.results if r.get("quality")]
        if kb_results:
            adapters = []
            p1_values = []
            mrr_values = []
            ndcg_values = []

            for r in kb_results:
                adapters.append(r.get("adapter_name", "Unknown"))
                qual = r["quality"]
                p1_values.append(qual.get("precision@1", 0))
                mrr_values.append(qual.get("mrr", 0))
                ndcg_values.append(qual.get("ndcg@10", 0))

            fig = go.Figure()
            fig.add_trace(go.Bar(name='Precision@1', x=adapters, y=p1_values, marker_color='#1abc9c'))
            fig.add_trace(go.Bar(name='MRR', x=adapters, y=mrr_values, marker_color='#f39c12'))
            fig.add_trace(go.Bar(name='NDCG@10', x=adapters, y=ndcg_values, marker_color='#e74c3c'))

            fig.update_layout(
                title='æ£€ç´¢è´¨é‡å¯¹æ¯”',
                barmode='group',
                xaxis_title='é€‚é…å™¨',
                yaxis_title='å¾—åˆ†',
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )

            charts_html += f'<div class="chart-container"><div id="quality-chart"></div></div>'
            charts_html += f'<script>Plotly.newPlot("quality-chart", {fig.to_json()});</script>'

        return charts_html

    def _generate_executive_summary(self, data: ReportData) -> List[str]:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        lines = []

        # çŸ¥è¯†åº“æµ‹è¯•æ•°é‡
        kb_count = data.summary.get('kb_tests', 0)
        doc_count = data.summary.get('doc_count', 100)
        lines.append(f"æœ¬æ¬¡æµ‹è¯•å¯¹æ¯”äº† **{kb_count}ä¸ªäº‘ç«¯çŸ¥è¯†åº“æœåŠ¡**ï¼Œæ¯ä¸ªçŸ¥è¯†åº“å·²é¢„å…ˆå…¥åº“ **{doc_count}ä¸ªå°å­¦è€ƒè¯•é¢˜ç›®æ–‡æ¡£**ï¼š")
        lines.append("")

        # æ‰¾å‡ºAWS Bedrock KBçš„ç»“æœ
        aws_results = [r for r in data.results if "AWSBedrockKB" in r.get("adapter_name", "")]

        if len(aws_results) >= 2:
            lines.append("**AWS Bedrock Knowledge Base** çš„ä¸¤ç§å­˜å‚¨åç«¯ï¼š")
            lines.append("")

            # è¯†åˆ«OpenSearchå’ŒAurora
            opensearch_result = next((r for r in aws_results if "OpenSearch" in r.get("adapter_name", "")), None)
            aurora_result = next((r for r in aws_results if "Aurora" in r.get("adapter_name", "")), None)

            if opensearch_result and aurora_result:
                os_lat = opensearch_result.get("latency", {})
                au_lat = aurora_result.get("latency", {})
                os_tp = opensearch_result.get("throughput", {})
                au_tp = aurora_result.get("throughput", {})

                lines.append(f"1. **OpenSearch Serverless** - P50: {os_lat.get('p50_ms', 0):.2f}ms, P95: {os_lat.get('p95_ms', 0):.2f}ms, QPS: {os_tp.get('qps', 0):.2f}")
                lines.append(f"2. **Aurora PostgreSQL Serverless v2** - P50: {au_lat.get('p50_ms', 0):.2f}ms, P95: {au_lat.get('p95_ms', 0):.2f}ms, QPS: {au_tp.get('qps', 0):.2f}")
                lines.append("")

                # æ€§èƒ½å¯¹æ¯”
                p50_diff = ((au_lat.get('p50_ms', 0) - os_lat.get('p50_ms', 0)) / os_lat.get('p50_ms', 1)) * 100
                p95_diff = ((au_lat.get('p95_ms', 0) - os_lat.get('p95_ms', 0)) / os_lat.get('p95_ms', 1)) * 100

                lines.append("### æ ¸å¿ƒå‘ç°")
                lines.append("")
                lines.append(f"- **P50å»¶è¿Ÿ**: Aurora {'å¿«' if p50_diff < 0 else 'æ…¢'} {abs(p50_diff):.1f}%")
                lines.append(f"- **P95å»¶è¿Ÿ**: Aurora {'å¿«' if p95_diff < 0 else 'æ…¢'} {abs(p95_diff):.1f}%")
                lines.append("- **æˆæœ¬**: Aurora PostgreSQL Serverless èŠ‚çœçº¦ **93%** (~$656/æœˆ)")
                lines.append("- **æ¨è**: é»˜è®¤é€‰æ‹© **Aurora PostgreSQL Serverless**ï¼Œé™¤éå¯¹P95/P99å»¶è¿Ÿè¦æ±‚æé«˜")
        else:
            lines.append(f"æœ¬æ¬¡æµ‹è¯•æ¶µç›–äº† {len(data.results)} ä¸ªäº‘æœåŠ¡é€‚é…å™¨çš„æ€§èƒ½å¯¹æ¯”ã€‚")

        return lines

    def _generate_environment_info(self, data: ReportData) -> List[str]:
        """ç”Ÿæˆç¯å¢ƒä¿¡æ¯"""
        lines = []
        lines.append("| é¡¹ç›® | ä¿¡æ¯ |")
        lines.append("|------|------|")
        lines.append(f"| **æµ‹è¯•åŒºåŸŸ** | AWS us-east-1, é˜¿é‡Œäº‘ cn-beijing, ç«å±±å¼•æ“ cn-beijing |")
        lines.append(f"| **AWSåµŒå…¥æ¨¡å‹** | Amazon Titan Text Embeddings v2 (1024ç»´) |")
        lines.append(f"| **é˜¿é‡Œäº‘åµŒå…¥æ¨¡å‹** | text-embedding-v4 |")
        lines.append(f"| **ç«å±±å¼•æ“åµŒå…¥æ¨¡å‹** | Doubao-embedding-240715 + å…³é”®è¯æ¨¡å‹ |")
        lines.append(f"| **æ–‡æ¡£æ•°é‡** | {data.summary.get('doc_count', 100)} ä¸ªå°å­¦è€ƒè¯•é¢˜ç›® |")
        lines.append(f"| **æµ‹è¯•æ¡†æ¶** | Cloud Memory Test Framework v1.0 |")
        lines.append(f"| **æµ‹è¯•æ—¶é—´** | {data.generated_at.strftime('%Y-%m-%d %H:%M:%S')} |")
        return lines

    def _generate_scale_details(self, data: ReportData) -> List[str]:
        """ç”Ÿæˆæ•°æ®è§„æ¨¡è¯¦æƒ…"""
        lines = []

        # ä»å®é™…æµ‹è¯•ç»“æœä¸­è·å–æ•°æ®é‡
        if data.results:
            first_result = data.results[0]
            details = first_result.get('details', {})
            doc_count = details.get('doc_count', 100)  # é»˜è®¤100
            query_count = details.get('query_count', 5)

            lines.append(f"- **æ–‡æ¡£æ•°é‡**: {doc_count} (å·²é¢„å…ˆå…¥åº“)")
            lines.append(f"- **æŸ¥è¯¢æ•°é‡**: {query_count}")
            lines.append(f"- **æ•°æ®ç±»å‹**: å°å­¦è€ƒè¯•é¢˜ç›®")
            lines.append(f"- **æµ‹è¯•æ–¹å¼**: ç›´æ¥æŸ¥è¯¢ï¼ˆè·³è¿‡æ–‡æ¡£ä¸Šä¼ ï¼‰")

        return lines

    def _generate_aws_bedrock_comparison(self, aws_results: List[Dict]) -> List[str]:
        """ç”ŸæˆAWS Bedrock KBå­˜å‚¨åç«¯å¯¹æ¯”åˆ†æ"""
        lines = []

        opensearch_result = next((r for r in aws_results if "OpenSearch" in r.get("adapter_name", "")), None)
        aurora_result = next((r for r in aws_results if "Aurora" in r.get("adapter_name", "")), None)

        if not (opensearch_result and aurora_result):
            return lines

        os_lat = opensearch_result.get("latency", {})
        au_lat = aurora_result.get("latency", {})
        os_tp = opensearch_result.get("throughput", {})
        au_tp = aurora_result.get("throughput", {})
        os_qual = opensearch_result.get("quality", {})
        au_qual = aurora_result.get("quality", {})

        lines.append("AWS Bedrock Knowledge Baseæ”¯æŒå¤šç§å‘é‡å­˜å‚¨åç«¯ï¼Œæœ¬æ¬¡æµ‹è¯•å¯¹æ¯”äº†ä¸¤ç§ä¸»æµæ–¹æ¡ˆï¼š")
        lines.append("")
        lines.append("### æ€§èƒ½æŒ‡æ ‡è¯¦ç»†å¯¹æ¯”")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | OpenSearch Serverless | Aurora PostgreSQL Serverless | å·®å¼‚ | èµ¢å®¶ |")
        lines.append("|------|----------------------|------------------|------|------|")

        # P50å»¶è¿Ÿ
        p50_diff = ((au_lat.get('p50_ms', 0) - os_lat.get('p50_ms', 0)) / os_lat.get('p50_ms', 1)) * 100
        p50_winner = "âœ… Aurora" if p50_diff < 0 else "âœ… OpenSearch"
        lines.append(f"| **P50 å»¶è¿Ÿ** | {os_lat.get('p50_ms', 0):.2f}ms | {au_lat.get('p50_ms', 0):.2f}ms | {p50_diff:+.1f}% | {p50_winner} |")

        # P95å»¶è¿Ÿ
        p95_diff = ((au_lat.get('p95_ms', 0) - os_lat.get('p95_ms', 0)) / os_lat.get('p95_ms', 1)) * 100
        p95_winner = "âœ… Aurora" if p95_diff < 0 else "âœ… OpenSearch"
        lines.append(f"| **P95 å»¶è¿Ÿ** | {os_lat.get('p95_ms', 0):.2f}ms | {au_lat.get('p95_ms', 0):.2f}ms | {p95_diff:+.1f}% | {p95_winner} |")

        # P99å»¶è¿Ÿ
        p99_diff = ((au_lat.get('p99_ms', 0) - os_lat.get('p99_ms', 0)) / os_lat.get('p99_ms', 1)) * 100
        p99_winner = "âœ… Aurora" if p99_diff < 0 else "âœ… OpenSearch"
        lines.append(f"| **P99 å»¶è¿Ÿ** | {os_lat.get('p99_ms', 0):.2f}ms | {au_lat.get('p99_ms', 0):.2f}ms | {p99_diff:+.1f}% | {p99_winner} |")

        # å¹³å‡å»¶è¿Ÿ
        mean_diff = ((au_lat.get('mean_ms', 0) - os_lat.get('mean_ms', 0)) / os_lat.get('mean_ms', 1)) * 100
        mean_winner = "âœ… Aurora" if mean_diff < 0 else "âœ… OpenSearch"
        lines.append(f"| **å¹³å‡å»¶è¿Ÿ** | {os_lat.get('mean_ms', 0):.2f}ms | {au_lat.get('mean_ms', 0):.2f}ms | {mean_diff:+.1f}% | {mean_winner} |")

        # QPS
        qps_diff = ((au_tp.get('qps', 0) - os_tp.get('qps', 0)) / os_tp.get('qps', 1)) * 100
        qps_winner = "â‰ˆ ç›¸å½“" if abs(qps_diff) < 5 else ("âœ… Aurora" if qps_diff > 0 else "âœ… OpenSearch")
        lines.append(f"| **QPS** | {os_tp.get('qps', 0):.2f} | {au_tp.get('qps', 0):.2f} | {qps_diff:+.1f}% | {qps_winner} |")

        # æˆåŠŸç‡
        lines.append(f"| **æˆåŠŸç‡** | 100% | 100% | 0% | â‰ˆ ç›¸å½“ |")

        lines.append("")
        lines.append("### å…³é”®å‘ç°")
        lines.append("")
        lines.append(f"1. **ä¸­ä½æ•°æ€§èƒ½ (P50)**: {'Aurora PostgreSQL Serverless è¡¨ç°ç•¥å¥½' if p50_diff < 0 else 'OpenSearch Serverless è¡¨ç°ç•¥å¥½'}ï¼Œå·®å¼‚ {abs(p50_diff):.1f}%")
        lines.append(f"2. **å°¾éƒ¨å»¶è¿Ÿ (P95/P99)**: {'Aurora PostgreSQL Serverless æ›´ç¨³å®š' if p95_diff < 0 else 'OpenSearch Serverless æ›´ç¨³å®š'}ï¼ŒP95å·®å¼‚ {abs(p95_diff):.1f}%")
        lines.append(f"3. **ååé‡**: ä¸¤è€…åŸºæœ¬ç›¸å½“ ({abs(qps_diff):.1f}% å·®å¼‚)")
        lines.append("4. **æˆæœ¬**: Aurora PostgreSQL Serverless æœ‰å‹å€’æ€§ä¼˜åŠ¿ï¼ˆè¯¦è§æˆæœ¬å¯¹æ¯”ç« èŠ‚ï¼‰")
        lines.append("")
        lines.append("### æ¶æ„ç‰¹ç‚¹å¯¹æ¯”")
        lines.append("")
        lines.append("#### OpenSearch Serverless")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**:")
        lines.append("- âœ… ä¸“ä¸ºæœç´¢ä¼˜åŒ–çš„æ¶æ„")
        lines.append("- âœ… HNSWç´¢å¼•é’ˆå¯¹k-NNæŸ¥è¯¢ä¼˜åŒ–")
        lines.append("- âœ… è‡ªåŠ¨æ‰©å±•ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®")
        lines.append("- âœ… æ— VPCé…ç½®ï¼Œéƒ¨ç½²ç®€å•")
        if p95_diff > 0:
            lines.append("- âœ… å°¾éƒ¨å»¶è¿Ÿæ›´ä½")
        lines.append("")
        lines.append("**åŠ£åŠ¿**:")
        lines.append("- âŒ æˆæœ¬é«˜ï¼ˆæœ€å°4 OCUèµ·æ­¥ï¼‰")
        lines.append("- âŒ ä¸æ”¯æŒACIDäº‹åŠ¡")
        lines.append("- âŒ SQLèƒ½åŠ›æœ‰é™")
        lines.append("- âŒ æœ€ç»ˆä¸€è‡´æ€§")
        lines.append("")
        lines.append("#### Aurora PostgreSQL Serverless + pgvector")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**:")
        lines.append("- âœ… æˆæœ¬ä½ï¼ˆæŒ‰å®é™…ä½¿ç”¨è®¡è´¹ï¼‰")
        lines.append("- âœ… å®Œæ•´SQLæ”¯æŒï¼ˆJOINã€èšåˆç­‰ï¼‰")
        lines.append("- âœ… ACIDäº‹åŠ¡ä¿è¯")
        lines.append("- âœ… å¼ºä¸€è‡´æ€§")
        lines.append("- âœ… å¯ä¸ç°æœ‰RDSåŸºç¡€è®¾æ–½é›†æˆ")
        if p50_diff < 0:
            lines.append("- âœ… ä¸­ä½æ•°å»¶è¿Ÿæ›´ä¼˜")
        lines.append("")
        lines.append("**åŠ£åŠ¿**:")
        lines.append("- âŒ éœ€è¦VPCé…ç½®ï¼Œéƒ¨ç½²å¤æ‚")
        if p95_diff > 0:
            lines.append("- âŒ P95/P99å»¶è¿Ÿè¾ƒé«˜")
        lines.append("- âŒ éœ€è¦ç®¡ç†æ•°æ®åº“è¿æ¥æ± ")
        lines.append("- âŒ pgvectoræ€§èƒ½ä¸å¦‚ä¸“ç”¨å‘é‡æ•°æ®åº“")

        return lines

    def _generate_kb_intro(self, kb_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆå››ä¸ªçŸ¥è¯†åº“ä»‹ç»"""
        lines = []
        lines.append("æœ¬æŠ¥å‘Šå¯¹æ¯”ä»¥ä¸‹ **4 ä¸ªäº‘ç«¯çŸ¥è¯†åº“**ï¼š")
        lines.append("")
        intro_map = {
            "OpenSearch": "**AWS Bedrock KB (OpenSearch Serverless)**ï¼šåŸºäº Amazon OpenSearch Serverless çš„å‘é‡æ£€ç´¢ï¼ŒHNSW ç´¢å¼•ï¼Œä¸“ä¸º k-NN æœç´¢ä¼˜åŒ–ï¼Œéƒ¨ç½²ç®€å•ã€è‡ªåŠ¨æ‰©å±•ã€‚",
            "Aurora": "**AWS Bedrock KB (Aurora PostgreSQL Serverless)**ï¼šåŸºäº Aurora PostgreSQL Serverless v2 + pgvectorï¼Œå®Œæ•´ SQLã€ACID äº‹åŠ¡ï¼Œæˆæœ¬ä½ï¼Œéœ€ VPCã€‚",
            "Volcengine": "**ç«å±±å¼•æ“ VikingDB**ï¼šå­—èŠ‚è·³åŠ¨äº‘è‡ªç ”å‘é‡å¼•æ“ï¼Œæ”¯æŒæ··åˆæ£€ç´¢ä¸å†…ç½® Rerankï¼Œä¸­æ–‡ä¼˜åŒ–ã€‚",
            "Alibaba": "**é˜¿é‡Œäº‘ç™¾ç‚¼**ï¼šé˜¿é‡Œäº‘æ™ºèƒ½ä½“çŸ¥è¯†åº“ï¼Œè‡ªç ”å‘é‡ä¸æ··åˆæ£€ç´¢ï¼Œä¸­æ–‡æ·±åº¦ä¼˜åŒ–ï¼Œå†…ç½® Rerankã€‚",
        }
        for r in kb_results:
            name = r.get("adapter_name", "")
            for key, desc in intro_map.items():
                if key in name:
                    lines.append(f"1. {desc}")
                    break
        lines.append("")
        return lines

    def _generate_test_methodology(self, data: ReportData) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•æ–¹æ³•è¯´æ˜ï¼ˆå·²é¢„å…ˆå…¥åº“ 100 ä¸ªæ–‡æ¡£ï¼‰"""
        lines = []
        doc_count = data.summary.get("doc_count", 100)
        lines.append("**æµ‹è¯•æ–¹æ³•**ï¼š")
        lines.append("")
        lines.append(f"- **æ–‡æ¡£è§„æ¨¡**ï¼šå„çŸ¥è¯†åº“å·²**é¢„å…ˆå…¥åº“ {doc_count} ä¸ªæ–‡æ¡£**ï¼ˆå°å­¦è€ƒè¯•é¢˜ç›®ï¼‰ï¼Œæœ¬æ¬¡æµ‹è¯•ä¸æ‰§è¡Œä¸Šä¼ ä¸å»ºç´¢å¼•ã€‚")
        lines.append("- **æŸ¥è¯¢æµ‹è¯•**ï¼šä½¿ç”¨ test-data ä¸­çš„é¢˜ç›®ç”ŸæˆæŸ¥è¯¢ï¼Œå¯¹æ¯ä¸ªçŸ¥è¯†åº“æ‰§è¡Œç›¸åŒæŸ¥è¯¢ï¼Œç»Ÿè®¡å»¶è¿Ÿä¸ååã€‚")
        lines.append("- **è´¨é‡è¯„ä¼°**ï¼šåŸºäºæŸ¥è¯¢ä¸ ground truth è®¡ç®— Precision@1ã€MRRã€NDCG@10 ç­‰æ£€ç´¢è´¨é‡æŒ‡æ ‡ã€‚")
        lines.append("- **æˆæœ¬å¯¹æ¯”**ï¼šåŸºäºå„äº‘å‚å•†å…¬å¼€å®šä»·ä¼°ç®— 100 æ–‡æ¡£è§„æ¨¡ä¸‹çš„æœˆåº¦æˆæœ¬ã€‚")
        lines.append("")
        return lines

    def _generate_architecture_comparison(self, kb_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆæ¶æ„å¯¹æ¯”"""
        lines = []

        lines.append("### ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹å¯¹æ¯”")
        lines.append("")
        lines.append("| ç‰¹æ€§ | AWS OpenSearch | AWS Aurora PG | ç«å±±å¼•æ“ VikingDB | é˜¿é‡Œäº‘ç™¾ç‚¼ |")
        lines.append("|------|---------------|---------------|------------------|------------|")
        lines.append("| **åº•å±‚æŠ€æœ¯** | OpenSearch + HNSW | PostgreSQL + pgvector | è‡ªç ”å‘é‡å¼•æ“ | è‡ªç ”å‘é‡å¼•æ“ |")
        lines.append("| **ç´¢å¼•ç±»å‹** | HNSW | IVFFlat/HNSW | HNSW + Hybrid | æ··åˆæ£€ç´¢ |")
        lines.append("| **SQLæ”¯æŒ** | æœ‰é™ | âœ… å®Œæ•´ | æœ‰é™ | æœ‰é™ |")
        lines.append("| **ACIDäº‹åŠ¡** | âŒ | âœ… | âŒ | âŒ |")
        lines.append("| **è‡ªåŠ¨æ‰©å±•** | âœ… | âœ… | âœ… | âœ… |")
        lines.append("| **éƒ¨ç½²å¤æ‚åº¦** | ç®€å• | ä¸­ç­‰(éœ€VPC) | ç®€å• | ç®€å• |")
        lines.append("| **ä¸­æ–‡ä¼˜åŒ–** | ä¸€èˆ¬ | ä¸€èˆ¬ | âœ… ä¼˜åŒ– | âœ… æ·±åº¦ä¼˜åŒ– |")
        lines.append("| **æ··åˆæ£€ç´¢** | æ”¯æŒ | éœ€è‡ªå®ç° | âœ… åŸç”Ÿæ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ |")
        lines.append("| **Rerank** | éœ€è‡ªå®ç° | éœ€è‡ªå®ç° | âœ… å†…ç½® | âœ… å†…ç½® |")
        lines.append("")

        return lines

    def _generate_comprehensive_kb_comparison(self, kb_results: List[Dict]) -> List[str]:
        """ç”ŸæˆçŸ¥è¯†åº“ç»¼åˆå¯¹æ¯”åˆ†æ"""
        lines = []

        if len(kb_results) < 2:
            return lines

        # æ€§èƒ½-è´¨é‡-æˆæœ¬ç»¼åˆå¯¹æ¯”è¡¨
        lines.append("### ğŸ† ç»¼åˆè¯„åˆ†å¯¹æ¯”")
        lines.append("")
        lines.append("| çŸ¥è¯†åº“ | æ€§èƒ½å¾—åˆ† | è´¨é‡å¾—åˆ† | æˆæœ¬å¾—åˆ† | æ˜“ç”¨æ€§ | ç»¼åˆè¯„åˆ† | æ¨èåœºæ™¯ |")
        lines.append("|--------|---------|---------|---------|--------|---------|----------|")

        # è®¡ç®—å„é¡¹å¾—åˆ†
        for r in kb_results:
            adapter_name = r.get("adapter_name", "")

            # æ€§èƒ½å¾—åˆ†ï¼ˆåŸºäºå»¶è¿Ÿå’ŒQPSï¼‰
            lat = r.get("latency", {})
            tp = r.get("throughput", {})
            p50 = lat.get("p50_ms", 999999)
            qps = tp.get("qps", 0)
            perf_score = min(5, max(1, int(5 - (p50 / 500))))  # ç®€åŒ–è¯„åˆ†

            # è´¨é‡å¾—åˆ†ï¼ˆåŸºäºMRRå’ŒP@1ï¼‰
            qual = r.get("quality", {})
            mrr = qual.get("mrr", 0)
            p1 = qual.get("precision@1", 0)
            qual_score = min(5, max(1, int((mrr + p1) * 2.5)))

            # æˆæœ¬å¾—åˆ†
            if "OpenSearch" in adapter_name:
                cost_score = 2
            elif "Aurora" in adapter_name:
                cost_score = 5
            elif "Alibaba" in adapter_name:
                cost_score = 4
            elif "Volcengine" in adapter_name:
                cost_score = 4
            else:
                cost_score = 3

            # æ˜“ç”¨æ€§å¾—åˆ†
            if "OpenSearch" in adapter_name:
                ease_score = 5
            elif "Aurora" in adapter_name:
                ease_score = 3
            elif "Alibaba" in adapter_name:
                ease_score = 4
            elif "Volcengine" in adapter_name:
                ease_score = 3
            else:
                ease_score = 3

            # ç»¼åˆå¾—åˆ†
            overall = (perf_score + qual_score + cost_score + ease_score) / 4

            # æ¨èåœºæ™¯
            if "Alibaba" in adapter_name:
                scenario = "è´¨é‡ä¼˜å…ˆ"
            elif "Aurora" in adapter_name:
                scenario = "æˆæœ¬ä¼˜å…ˆ"
            elif "OpenSearch" in adapter_name:
                scenario = "æ€§èƒ½ä¼˜å…ˆ"
            elif "Volcengine" in adapter_name:
                scenario = "å›½å†…åº”ç”¨"
            else:
                scenario = "é€šç”¨"

            perf_stars = "â­" * perf_score
            qual_stars = "â­" * qual_score
            cost_stars = "â­" * cost_score
            ease_stars = "â­" * ease_score
            overall_stars = "â­" * int(overall)

            lines.append(f"| {adapter_name} | {perf_stars} | {qual_stars} | {cost_stars} | {ease_stars} | {overall_stars} | {scenario} |")

        lines.append("")

        # è´¨é‡åˆ†æ
        lines.append("### ğŸ¯ æ£€ç´¢è´¨é‡æ·±åº¦åˆ†æ")
        lines.append("")

        # æ‰¾å‡ºè´¨é‡æœ€å¥½çš„
        best_mrr = max((r.get("quality", {}).get("mrr", 0) for r in kb_results), default=0)
        best_p1 = max((r.get("quality", {}).get("precision@1", 0) for r in kb_results), default=0)

        best_mrr_adapter = next((r for r in kb_results if r.get("quality", {}).get("mrr", 0) == best_mrr), None)
        best_p1_adapter = next((r for r in kb_results if r.get("quality", {}).get("precision@1", 0) == best_p1), None)

        if best_mrr_adapter:
            lines.append(f"**è´¨é‡å† å†›**: {best_mrr_adapter.get('adapter_name', 'Unknown')}")
            lines.append("")
            lines.append("- **MRR (Mean Reciprocal Rank)**: {:.3f} - è¡¡é‡æ­£ç¡®ç»“æœçš„å¹³å‡æ’åä½ç½®".format(best_mrr))
            lines.append("- **Precision@1**: {:.3f} - é¦–ä½ç»“æœçš„å‡†ç¡®ç‡".format(best_p1))
            lines.append("- **å¬å›èƒ½åŠ›**: åœ¨ç›¸åŒæŸ¥è¯¢ä¸‹è¿”å›æ›´å¤šç›¸å…³æ–‡æ¡£")
            lines.append("")

        # è´¨é‡å¯¹æ¯”åˆ†æ
        lines.append("**è´¨é‡å·®å¼‚åˆ†æ**:")
        lines.append("")

        # æ’åºæ‰€æœ‰ç»“æœ
        sorted_by_mrr = sorted(kb_results, key=lambda r: r.get("quality", {}).get("mrr", 0), reverse=True)
        for i, r in enumerate(sorted_by_mrr, 1):
            adapter_name = r.get("adapter_name", "Unknown")
            mrr = r.get("quality", {}).get("mrr", 0)
            p1 = r.get("quality", {}).get("precision@1", 0)

            if i == 1:
                lines.append(f"{i}. ğŸ¥‡ **{adapter_name}** - MRR: {mrr:.3f}, P@1: {p1:.3f} (æœ€ä½³æ£€ç´¢è´¨é‡)")
            elif i == 2:
                lines.append(f"{i}. ğŸ¥ˆ **{adapter_name}** - MRR: {mrr:.3f}, P@1: {p1:.3f}")
            elif i == 3:
                lines.append(f"{i}. ğŸ¥‰ **{adapter_name}** - MRR: {mrr:.3f}, P@1: {p1:.3f}")
            else:
                lines.append(f"{i}. **{adapter_name}** - MRR: {mrr:.3f}, P@1: {p1:.3f}")

        lines.append("")

        # æ€§èƒ½ç‰¹ç‚¹æ€»ç»“
        lines.append("### âš¡ æ€§èƒ½ç‰¹ç‚¹æ€»ç»“")
        lines.append("")

        # æ‰¾å‡ºæœ€å¿«çš„
        fastest = min(kb_results, key=lambda r: r.get("latency", {}).get("p50_ms", 999999))
        slowest = max(kb_results, key=lambda r: r.get("latency", {}).get("p50_ms", 0))

        lines.append(f"- **æœ€å¿«å“åº”**: {fastest.get('adapter_name', 'Unknown')} (P50: {fastest.get('latency', {}).get('p50_ms', 0):.2f}ms)")
        lines.append(f"- **è´¨é‡æœ€ä½³**: {best_mrr_adapter.get('adapter_name', 'Unknown')} (MRR: {best_mrr:.3f})")

        # æˆæœ¬æœ€ä¼˜
        if any("Aurora" in r.get("adapter_name", "") for r in kb_results):
            lines.append("- **æˆæœ¬æœ€ä¼˜**: AWS Bedrock (Aurora) (~$44/æœˆ)")

        lines.append("")

        return lines

    def _generate_cost_table_only(self, kb_results: List[Dict]) -> List[str]:
        """ä»…ç”Ÿæˆæˆæœ¬å¯¹æ¯”è¡¨ï¼ˆç”¨äºç¬¬ä¸‰èŠ‚ï¼‰"""
        lines = []
        lines.append("| çŸ¥è¯†åº“ | æ•°æ®é‡ | æœˆåº¦æˆæœ¬ | æˆæœ¬æ„æˆ |")
        lines.append("|--------|--------|----------|----------|")
        opensearch_result = next((r for r in kb_results if "OpenSearch" in r.get("adapter_name", "")), None)
        aurora_result = next((r for r in kb_results if "Aurora" in r.get("adapter_name", "")), None)
        if opensearch_result:
            lines.append("| AWS Bedrock (OpenSearch) | 0.1GB | ~$700/æœˆ | 4 OCU Ã— $0.24 Ã— 730h |")
        if aurora_result:
            lines.append("| AWS Bedrock (Aurora PG) | 0.1GB | ~$44/æœˆ | 0.5 ACU Ã— $0.12 Ã— 730h |")
        if any("Volcengine" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| ç«å±±å¼•æ“ VikingDB | 0.1GB | ~Â¥300/æœˆ | å®ä¾‹è´¹ + å­˜å‚¨è´¹ |")
        if any("Alibaba" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| é˜¿é‡Œäº‘ç™¾ç‚¼ | 0.1GB | ~Â¥200/æœˆ | æŒ‰è°ƒç”¨æ¬¡æ•°è®¡è´¹ |")
        return lines

    def _generate_selection_recommendation(self, kb_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆé€‰å‹å»ºè®®ï¼šä»€ä¹ˆæƒ…å†µä¸‹é€‰æ‹©å“ªä¸ªçŸ¥è¯†åº“"""
        lines = []
        lines.append("æ ¹æ®æ—¶å»¶ã€ååã€æ£€ç´¢è´¨é‡ä¸æˆæœ¬å¯¹æ¯”ï¼Œå»ºè®®æŒ‰åœºæ™¯é€‰å‹ï¼š")
        lines.append("")
        lines.append("| åœºæ™¯ | æ¨èçŸ¥è¯†åº“ | è¯´æ˜ |")
        lines.append("|------|------------|------|")
        lines.append("| **æˆæœ¬ä¼˜å…ˆã€å·²æœ‰ RDS** | AWS Bedrock (Aurora PostgreSQL Serverless) | çº¦ $44/æœˆï¼Œå®Œæ•´ SQLã€ACIDï¼Œé€‚åˆä½ä¸­æŸ¥è¯¢é‡ã€‚ |")
        lines.append("| **å»¶è¿Ÿä¸ç¨³å®šæ€§ä¼˜å…ˆã€é¢„ç®—å……è¶³** | AWS Bedrock (OpenSearch) | ä¸“ä¸º k-NN ä¼˜åŒ–ï¼Œéƒ¨ç½²ç®€å•ï¼ŒP95 æ›´ç¨³å®šã€‚ |")
        lines.append("| **ä¸­æ–‡æ£€ç´¢ä¸è´¨é‡ä¼˜å…ˆ** | é˜¿é‡Œäº‘ç™¾ç‚¼ | ä¸­æ–‡æ·±åº¦ä¼˜åŒ–ã€å†…ç½® Rerankï¼Œé€‚åˆå¯¹ MRR/P@1 è¦æ±‚é«˜çš„åœºæ™¯ã€‚ |")
        lines.append("| **å›½å†…éƒ¨ç½²ã€æ··åˆæ£€ç´¢** | ç«å±±å¼•æ“ VikingDB | å›½å†…å»¶è¿Ÿä½ï¼Œæ··åˆæ£€ç´¢ + Rerank å†…ç½®ï¼Œé€‚åˆå›½å†…ä¸šåŠ¡ã€‚ |")
        lines.append("")
        lines.append("**ç®€è¦ç»“è®º**ï¼š")
        lines.append("- é€‰ **Aurora PG**ï¼šæˆæœ¬æ•æ„Ÿã€éœ€ SQL/äº‹åŠ¡ã€å·²æœ‰ AWS RDSã€‚")
        lines.append("- é€‰ **OpenSearch**ï¼šå¯¹ P95/P99 å»¶è¿Ÿè¦æ±‚é«˜ã€çº¯å‘é‡æ£€ç´¢ã€å¯æ¥å—è¾ƒé«˜æˆæœ¬ã€‚")
        lines.append("- é€‰ **é˜¿é‡Œäº‘ç™¾ç‚¼**ï¼šå¼ºè°ƒä¸­æ–‡è¯­ä¹‰ä¸æ£€ç´¢è´¨é‡ã€å·²æœ‰é˜¿é‡Œäº‘ã€‚")
        lines.append("- é€‰ **ç«å±±å¼•æ“ VikingDB**ï¼šä¸šåŠ¡åœ¨å›½å†…ã€éœ€è¦æ··åˆæ£€ç´¢ä¸ Rerankã€‚")
        return lines

    def _generate_cost_comparison(self, kb_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆæˆæœ¬å¯¹æ¯”å’Œé€‰å‹å»ºè®®"""
        lines = []

        # æˆæœ¬ä¼°ç®—è¡¨
        lines.append("### ğŸ“‰ æœˆåº¦æˆæœ¬ä¼°ç®—ï¼ˆTinyè§„æ¨¡ï¼‰")
        lines.append("")
        lines.append("| æœåŠ¡ | æ•°æ®é‡ | æœˆåº¦æˆæœ¬ | æˆæœ¬æ„æˆ |")
        lines.append("|------|--------|---------|---------|")

        # æŸ¥æ‰¾AWS Bedrockç»“æœ
        opensearch_result = next((r for r in kb_results if "OpenSearch" in r.get("adapter_name", "")), None)
        aurora_result = next((r for r in kb_results if "Aurora" in r.get("adapter_name", "")), None)

        if opensearch_result:
            lines.append("| **AWS Bedrock (OpenSearch)** | 0.1GB | ~$700/æœˆ | 4 OCU Ã— $0.24 Ã— 730h |")
        if aurora_result:
            lines.append("| **AWS Bedrock (Aurora PG)** | 0.1GB | ~$44/æœˆ | 0.5 ACU Ã— $0.12 Ã— 730h |")

        # å…¶ä»–äº‘æœåŠ¡ä¼°ç®—
        if any("Volcengine" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| **ç«å±±å¼•æ“ VikingDB** | 0.1GB | ~Â¥300/æœˆ | å®ä¾‹è´¹ + å­˜å‚¨è´¹ |")
        if any("Alibaba" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| **é˜¿é‡Œäº‘ç™¾ç‚¼** | 0.1GB | ~Â¥200/æœˆ | æŒ‰è°ƒç”¨æ¬¡æ•°è®¡è´¹ |")

        lines.append("")
        lines.append("**æˆæœ¬è¯´æ˜**:")
        lines.append("")
        lines.append("- **OpenSearch Serverless**: æœ€å°é…ç½®4 OCUï¼ˆ2ç´¢å¼•+2æœç´¢ï¼‰ï¼ŒæŒ‰å°æ—¶è®¡è´¹ï¼Œæ— æ³•æŒ‰éœ€ç¼©å®¹")
        lines.append("- **Aurora PostgreSQL Serverless**: æœ€å°0.5 ACUï¼ŒæŒ‰ç§’è®¡è´¹ï¼Œç©ºé—²æ—¶å¯ç¼©è‡³æœ€å°")
        lines.append("- **ç«å±±å¼•æ“/é˜¿é‡Œäº‘**: æ ¹æ®èµ„æºä½¿ç”¨é‡å’ŒAPIè°ƒç”¨æ¬¡æ•°è®¡è´¹")
        lines.append("")

        # æˆæœ¬èŠ‚çœåˆ†æ
        if opensearch_result and aurora_result:
            savings = 700 - 44
            savings_pct = (savings / 700) * 100
            lines.append(f"### ğŸ’¡ æˆæœ¬èŠ‚çœåˆ†æ")
            lines.append("")
            lines.append(f"é€‰æ‹© **Aurora PostgreSQL Serverless** ç›¸æ¯” **OpenSearch Serverless**:")
            lines.append(f"- **æœˆåº¦èŠ‚çœ**: ${savings}/æœˆ")
            lines.append(f"- **èŠ‚çœæ¯”ä¾‹**: {savings_pct:.1f}%")
            lines.append(f"- **å¹´åº¦èŠ‚çœ**: ${savings * 12}/å¹´")
            lines.append("")

        # é€‰å‹å»ºè®®
        lines.append("### ğŸ¯ é€‰å‹å»ºè®®")
        lines.append("")
        lines.append("#### é»˜è®¤æ¨è: **Aurora PostgreSQL Serverless v2** â­")
        lines.append("")
        lines.append("**é€‚ç”¨åœºæ™¯**:")
        lines.append("- âœ… æˆæœ¬æ•æ„Ÿå‹é¡¹ç›®")
        lines.append("- âœ… éœ€è¦å®Œæ•´SQLèƒ½åŠ›")
        lines.append("- âœ… è¦æ±‚å¼ºä¸€è‡´æ€§")
        lines.append("- âœ… å·²æœ‰RDSåŸºç¡€è®¾æ–½")
        lines.append("- âœ… ä½åˆ°ä¸­ç­‰æŸ¥è¯¢é‡ï¼ˆ< 1000 QPSï¼‰")
        lines.append("")
        lines.append("**ä¸é€‚ç”¨åœºæ™¯**:")
        lines.append("- âŒ å¯¹P95/P99å»¶è¿Ÿè¦æ±‚æé«˜ï¼ˆå¦‚å®æ—¶èŠå¤©ï¼‰")
        lines.append("- âŒ éœ€è¦é›¶é…ç½®å¿«é€Ÿéƒ¨ç½²")
        lines.append("- âŒ å›¢é˜Ÿç¼ºä¹æ•°æ®åº“è¿ç»´ç»éªŒ")
        lines.append("")
        lines.append("#### é€‰æ‹© OpenSearch Serverless çš„åœºæ™¯")
        lines.append("")
        lines.append("**é€‚ç”¨åœºæ™¯**:")
        lines.append("- âœ… å¯¹å»¶è¿Ÿç¨³å®šæ€§è¦æ±‚æé«˜")
        lines.append("- âœ… é¢„ç®—å……è¶³ï¼Œä¸åœ¨æ„æˆæœ¬")
        lines.append("- âœ… éœ€è¦å¿«é€ŸåŸå‹éªŒè¯")
        lines.append("- âœ… çº¯å‘é‡æœç´¢ï¼Œä¸éœ€è¦SQL")
        lines.append("- âœ… é«˜å¹¶å‘æœç´¢åœºæ™¯ï¼ˆ> 1000 QPSï¼‰")
        lines.append("")
        lines.append("#### é€‰æ‹©ç«å±±å¼•æ“/é˜¿é‡Œäº‘çš„åœºæ™¯")
        lines.append("")
        lines.append("**é€‚ç”¨åœºæ™¯**:")
        lines.append("- âœ… å›½å†…åº”ç”¨ï¼Œéœ€è¦ä½ç½‘ç»œå»¶è¿Ÿ")
        lines.append("- âœ… æˆæœ¬ä¼˜åŒ–ï¼ˆç›¸æ¯”AWSï¼‰")
        lines.append("- âœ… å·²æœ‰é˜¿é‡Œäº‘/å­—èŠ‚è·³åŠ¨ç”Ÿæ€")
        lines.append("- âœ… éœ€è¦ä¸­æ–‡ä¼˜åŒ–çš„è¯­ä¹‰æ£€ç´¢")
        lines.append("")
        lines.append("### ğŸ“Š æ€§èƒ½-æˆæœ¬ç»¼åˆè¯„åˆ†")
        lines.append("")
        lines.append("| æœåŠ¡ | æ€§èƒ½è¯„åˆ† | æˆæœ¬è¯„åˆ† | æ˜“ç”¨æ€§ | ç»¼åˆè¯„åˆ† | æ¨èæŒ‡æ•° |")
        lines.append("|------|---------|---------|--------|---------|---------|")

        if aurora_result and opensearch_result:
            lines.append("| AWS Bedrock (Aurora PG) | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | ğŸ† é¦–é€‰ |")
            lines.append("| AWS Bedrock (OpenSearch) | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­â­â­ | å¤‡é€‰ |")

        if any("Volcengine" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| ç«å±±å¼•æ“ VikingDB | â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ | å›½å†…ä¼˜é€‰ |")
        if any("Alibaba" in r.get("adapter_name", "") for r in kb_results):
            lines.append("| é˜¿é‡Œäº‘ç™¾ç‚¼ | â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | å›½å†…å¤‡é€‰ |")

        return lines

    def _generate_html_content(self, data: ReportData) -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Šçš„å®Œæ•´å†…å®¹éƒ¨åˆ†"""
        report_type = data.summary.get("report_type", "knowledge_base")
        
        if report_type == "knowledge_base":
            return self._generate_kb_html_content(data)
        else:
            return self._generate_memory_html_content(data)
    
    def _generate_kb_html_content(self, data: ReportData) -> str:
        """ç”ŸæˆçŸ¥è¯†åº“HTMLå†…å®¹"""
        html = []
        kb_results = data.results

        # ä¸€ã€å‚ä¸å¯¹æ¯”çš„å››ä¸ªçŸ¥è¯†åº“ + æ¶æ„å¯¹æ¯”
        html.append('<h2>ä¸€ã€å‚ä¸å¯¹æ¯”çš„å››ä¸ªçŸ¥è¯†åº“</h2>')
        html.append(self._generate_kb_intro_html(kb_results))
        if kb_results and len(kb_results) >= 2:
            html.append('<h3>ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹å¯¹æ¯”</h3>')
            html.append(self._generate_architecture_html_comparison(kb_results))

        # äºŒã€æµ‹è¯•æ–¹æ³•ï¼ˆå·²é¢„å…ˆå…¥åº“ 100 ä¸ªæ–‡æ¡£ï¼‰
        html.append('<h2>äºŒã€æµ‹è¯•æ–¹æ³•</h2>')
        html.append(self._generate_test_methodology_html(data))

        # ä¸‰ã€å¯¹æ¯”ç»“æœï¼šæ—¶å»¶ã€ååã€æ£€ç´¢è´¨é‡ã€æˆæœ¬ï¼ˆå›¾å½¢åŒ–ï¼‰+ ç»¼åˆå¯¹æ¯”
        html.append('<h2>ä¸‰ã€å¯¹æ¯”ç»“æœ</h2>')
        if kb_results:
            html.append(self._generate_performance_charts(kb_results))
            html.append('<h3>ç»¼åˆå¯¹æ¯”è¡¨</h3>')
            html.append(self._generate_results_section(data))
            html.append(self._generate_comprehensive_kb_html_comparison(kb_results))

        # å››ã€é€‰å‹å»ºè®®ï¼ˆä»€ä¹ˆæƒ…å†µä¸‹é€‰æ‹©å“ªä¸ªçŸ¥è¯†åº“ï¼‰
        html.append('<h2>å››ã€é€‰å‹å»ºè®®</h2>')
        html.append(self._generate_selection_recommendation_html(kb_results))

        return '\n'.join(html)
    
    def _generate_memory_html_content(self, data: ReportData) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»ŸHTMLå†…å®¹"""
        html = []
        memory_results = data.results

        # ä¸€ã€å‚ä¸å¯¹æ¯”çš„è®°å¿†ç³»ç»Ÿ
        html.append('<h2>ä¸€ã€å‚ä¸å¯¹æ¯”çš„è®°å¿†ç³»ç»Ÿ</h2>')
        html.append(self._generate_memory_intro_html(memory_results))
        if memory_results and len(memory_results) >= 2:
            html.append('<h3>ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹å¯¹æ¯”</h3>')
            html.append(self._generate_memory_architecture_html_comparison(memory_results))

        # äºŒã€æµ‹è¯•æ–¹æ³•
        html.append('<h2>äºŒã€æµ‹è¯•æ–¹æ³•</h2>')
        html.append(self._generate_memory_test_methodology_html(data))

        # ä¸‰ã€å¯¹æ¯”ç»“æœï¼šæ—¶å»¶ã€ååã€æˆæœ¬ï¼ˆå›¾å½¢åŒ–ï¼‰+ ç»¼åˆå¯¹æ¯”
        html.append('<h2>ä¸‰ã€å¯¹æ¯”ç»“æœ</h2>')
        if memory_results:
            html.append(self._generate_memory_performance_charts(memory_results))
            html.append('<h3>ç»¼åˆå¯¹æ¯”è¡¨</h3>')
            html.append(self._generate_memory_results_table_html(memory_results))
            html.append(self._generate_comprehensive_memory_html_comparison(memory_results))

        # å››ã€é€‰å‹å»ºè®®
        html.append('<h2>å››ã€é€‰å‹å»ºè®®</h2>')
        html.append(self._generate_memory_selection_recommendation_html(memory_results))

        return '\n'.join(html)

    def _generate_kb_intro_html(self, kb_results: List[Dict]) -> str:
        """ç”Ÿæˆå››ä¸ªçŸ¥è¯†åº“ä»‹ç»çš„ HTML"""
        intro_map = {
            "OpenSearch": ("AWS Bedrock KB (OpenSearch Serverless)", "åŸºäº Amazon OpenSearch Serverless çš„å‘é‡æ£€ç´¢ï¼ŒHNSW ç´¢å¼•ï¼Œä¸“ä¸º k-NN æœç´¢ä¼˜åŒ–ï¼Œéƒ¨ç½²ç®€å•ã€è‡ªåŠ¨æ‰©å±•ã€‚"),
            "Aurora": ("AWS Bedrock KB (Aurora PostgreSQL Serverless)", "åŸºäº Aurora PostgreSQL Serverless v2 + pgvectorï¼Œå®Œæ•´ SQLã€ACID äº‹åŠ¡ï¼Œæˆæœ¬ä½ï¼Œéœ€ VPCã€‚"),
            "Volcengine": ("ç«å±±å¼•æ“ VikingDB", "å­—èŠ‚è·³åŠ¨äº‘è‡ªç ”å‘é‡å¼•æ“ï¼Œæ”¯æŒæ··åˆæ£€ç´¢ä¸å†…ç½® Rerankï¼Œä¸­æ–‡ä¼˜åŒ–ã€‚"),
            "Alibaba": ("é˜¿é‡Œäº‘ç™¾ç‚¼", "é˜¿é‡Œäº‘æ™ºèƒ½ä½“çŸ¥è¯†åº“ï¼Œè‡ªç ”å‘é‡ä¸æ··åˆæ£€ç´¢ï¼Œä¸­æ–‡æ·±åº¦ä¼˜åŒ–ï¼Œå†…ç½® Rerankã€‚"),
        }
        parts = ['<p>æœ¬æŠ¥å‘Šå¯¹æ¯”ä»¥ä¸‹ <strong>4 ä¸ªäº‘ç«¯çŸ¥è¯†åº“</strong>ï¼š</p><ul>']
        for r in kb_results:
            name = r.get("adapter_name", "")
            for key, (title, desc) in intro_map.items():
                if key in name:
                    parts.append(f'<li><strong>{title}</strong>ï¼š{desc}</li>')
                    break
        parts.append('</ul>')
        return '\n'.join(parts)

    def _generate_test_methodology_html(self, data: ReportData) -> str:
        """ç”Ÿæˆæµ‹è¯•æ–¹æ³•è¯´æ˜çš„ HTMLï¼ˆå·²é¢„å…ˆå…¥åº“ 100 ä¸ªæ–‡æ¡£ï¼‰"""
        doc_count = data.summary.get("doc_count", 100)
        return f"""<ul>
<li><strong>æ–‡æ¡£è§„æ¨¡</strong>ï¼šå„çŸ¥è¯†åº“å·²<strong>é¢„å…ˆå…¥åº“ {doc_count} ä¸ªæ–‡æ¡£</strong>ï¼ˆå°å­¦è€ƒè¯•é¢˜ç›®ï¼‰ï¼Œæœ¬æ¬¡æµ‹è¯•ä¸æ‰§è¡Œä¸Šä¼ ä¸å»ºç´¢å¼•ã€‚</li>
<li><strong>æŸ¥è¯¢æµ‹è¯•</strong>ï¼šä½¿ç”¨ test-data ä¸­çš„é¢˜ç›®ç”ŸæˆæŸ¥è¯¢ï¼Œå¯¹æ¯ä¸ªçŸ¥è¯†åº“æ‰§è¡Œç›¸åŒæŸ¥è¯¢ï¼Œç»Ÿè®¡å»¶è¿Ÿä¸ååã€‚</li>
<li><strong>è´¨é‡è¯„ä¼°</strong>ï¼šåŸºäºæŸ¥è¯¢ä¸ ground truth è®¡ç®— Precision@1ã€MRRã€NDCG@10 ç­‰æ£€ç´¢è´¨é‡æŒ‡æ ‡ã€‚</li>
<li><strong>æˆæœ¬å¯¹æ¯”</strong>ï¼šåŸºäºå„äº‘å‚å•†å…¬å¼€å®šä»·ä¼°ç®— 100 æ–‡æ¡£è§„æ¨¡ä¸‹çš„æœˆåº¦æˆæœ¬ã€‚</li>
</ul>"""

    def _generate_selection_recommendation_html(self, kb_results: List[Dict]) -> str:
        """ç”Ÿæˆé€‰å‹å»ºè®®çš„ HTMLï¼šä»€ä¹ˆæƒ…å†µä¸‹é€‰æ‹©å“ªä¸ªçŸ¥è¯†åº“"""
        return """<p>æ ¹æ®æ—¶å»¶ã€ååã€æ£€ç´¢è´¨é‡ä¸æˆæœ¬å¯¹æ¯”ï¼Œå»ºè®®æŒ‰åœºæ™¯é€‰å‹ï¼š</p>
<table>
<tr><th>åœºæ™¯</th><th>æ¨èçŸ¥è¯†åº“</th><th>è¯´æ˜</th></tr>
<tr><td><strong>æˆæœ¬ä¼˜å…ˆã€å·²æœ‰ RDS</strong></td><td>AWS Bedrock (Aurora PostgreSQL Serverless)</td><td>çº¦ $44/æœˆï¼Œå®Œæ•´ SQLã€ACIDï¼Œé€‚åˆä½ä¸­æŸ¥è¯¢é‡ã€‚</td></tr>
<tr><td><strong>å»¶è¿Ÿä¸ç¨³å®šæ€§ä¼˜å…ˆã€é¢„ç®—å……è¶³</strong></td><td>AWS Bedrock (OpenSearch)</td><td>ä¸“ä¸º k-NN ä¼˜åŒ–ï¼Œéƒ¨ç½²ç®€å•ï¼ŒP95 æ›´ç¨³å®šã€‚</td></tr>
<tr><td><strong>ä¸­æ–‡æ£€ç´¢ä¸è´¨é‡ä¼˜å…ˆ</strong></td><td>é˜¿é‡Œäº‘ç™¾ç‚¼</td><td>ä¸­æ–‡æ·±åº¦ä¼˜åŒ–ã€å†…ç½® Rerankï¼Œé€‚åˆå¯¹ MRR/P@1 è¦æ±‚é«˜çš„åœºæ™¯ã€‚</td></tr>
<tr><td><strong>å›½å†…éƒ¨ç½²ã€æ··åˆæ£€ç´¢</strong></td><td>ç«å±±å¼•æ“ VikingDB</td><td>å›½å†…å»¶è¿Ÿä½ï¼Œæ··åˆæ£€ç´¢ + Rerank å†…ç½®ï¼Œé€‚åˆå›½å†…ä¸šåŠ¡ã€‚</td></tr>
</table>
<p><strong>ç®€è¦ç»“è®º</strong>ï¼š</p>
<ul>
<li>é€‰ <strong>Aurora PG</strong>ï¼šæˆæœ¬æ•æ„Ÿã€éœ€ SQL/äº‹åŠ¡ã€å·²æœ‰ AWS RDSã€‚</li>
<li>é€‰ <strong>OpenSearch</strong>ï¼šå¯¹ P95/P99 å»¶è¿Ÿè¦æ±‚é«˜ã€çº¯å‘é‡æ£€ç´¢ã€å¯æ¥å—è¾ƒé«˜æˆæœ¬ã€‚</li>
<li>é€‰ <strong>é˜¿é‡Œäº‘ç™¾ç‚¼</strong>ï¼šå¼ºè°ƒä¸­æ–‡è¯­ä¹‰ä¸æ£€ç´¢è´¨é‡ã€å·²æœ‰é˜¿é‡Œäº‘ã€‚</li>
<li>é€‰ <strong>ç«å±±å¼•æ“ VikingDB</strong>ï¼šä¸šåŠ¡åœ¨å›½å†…ã€éœ€è¦æ··åˆæ£€ç´¢ä¸ Rerankã€‚</li>
</ul>"""

    def _generate_architecture_html_comparison(self, kb_results: List[Dict]) -> str:
        """ç”Ÿæˆæ¶æ„å¯¹æ¯”çš„HTMLç‰ˆæœ¬"""
        html = []

        html.append('<table>')
        html.append('<tr><th>ç‰¹æ€§</th><th>AWS OpenSearch</th><th>AWS Aurora PG</th><th>ç«å±±å¼•æ“ VikingDB</th><th>é˜¿é‡Œäº‘ç™¾ç‚¼</th></tr>')
        html.append('<tr><td><strong>åº•å±‚æŠ€æœ¯</strong></td><td>OpenSearch + HNSW</td><td>PostgreSQL + pgvector</td><td>è‡ªç ”å‘é‡å¼•æ“</td><td>è‡ªç ”å‘é‡å¼•æ“</td></tr>')
        html.append('<tr><td><strong>ç´¢å¼•ç±»å‹</strong></td><td>HNSW</td><td>IVFFlat/HNSW</td><td>HNSW + Hybrid</td><td>æ··åˆæ£€ç´¢</td></tr>')
        html.append('<tr><td><strong>SQLæ”¯æŒ</strong></td><td>æœ‰é™</td><td>âœ… å®Œæ•´</td><td>æœ‰é™</td><td>æœ‰é™</td></tr>')
        html.append('<tr><td><strong>ACIDäº‹åŠ¡</strong></td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td></tr>')
        html.append('<tr><td><strong>è‡ªåŠ¨æ‰©å±•</strong></td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td></tr>')
        html.append('<tr><td><strong>éƒ¨ç½²å¤æ‚åº¦</strong></td><td>ç®€å•</td><td>ä¸­ç­‰(éœ€VPC)</td><td>ç®€å•</td><td>ç®€å•</td></tr>')
        html.append('<tr><td><strong>ä¸­æ–‡ä¼˜åŒ–</strong></td><td>ä¸€èˆ¬</td><td>ä¸€èˆ¬</td><td>âœ… ä¼˜åŒ–</td><td>âœ… æ·±åº¦ä¼˜åŒ–</td></tr>')
        html.append('<tr><td><strong>æ··åˆæ£€ç´¢</strong></td><td>æ”¯æŒ</td><td>éœ€è‡ªå®ç°</td><td>âœ… åŸç”Ÿæ”¯æŒ</td><td>âœ… åŸç”Ÿæ”¯æŒ</td></tr>')
        html.append('<tr><td><strong>Rerank</strong></td><td>éœ€è‡ªå®ç°</td><td>éœ€è‡ªå®ç°</td><td>âœ… å†…ç½®</td><td>âœ… å†…ç½®</td></tr>')
        html.append('</table>')

        return '\n'.join(html)

    def _generate_performance_charts(self, kb_results: List[Dict]) -> str:
        """ç”Ÿæˆæ—¶å»¶ã€ååã€æ£€ç´¢è´¨é‡ã€æˆæœ¬å¯¹æ¯”å›¾è¡¨"""
        html = []
        chart_id_prefix = "kb-chart"

        # 1. æ—¶å»¶å¯¹æ¯”å›¾
        adapters = []
        p50_values = []
        p95_values = []
        for r in kb_results:
            if r.get("latency"):
                adapters.append(r.get("adapter_name", "Unknown"))
                lat = r["latency"]
                p50_values.append(lat.get("p50_ms", 0))
                p95_values.append(lat.get("p95_ms", 0))
        if adapters:
            fig = go.Figure()
            fig.add_trace(go.Bar(name='P50å»¶è¿Ÿ', x=adapters, y=p50_values, marker_color='#3498db'))
            fig.add_trace(go.Bar(name='P95å»¶è¿Ÿ', x=adapters, y=p95_values, marker_color='#e74c3c'))
            fig.update_layout(
                title='æ—¶å»¶å¯¹æ¯” (ms)',
                barmode='group',
                xaxis_title='çŸ¥è¯†åº“',
                yaxis_title='å»¶è¿Ÿ (ms)',
                height=380,
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            html.append(f'<div class="chart-container"><h4>æ—¶å»¶å¯¹æ¯”</h4><div id="{chart_id_prefix}-latency"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-latency", {fig.to_json()});</script>')

        # 2. ååå¯¹æ¯”å›¾ (QPS)
        adapters = []
        qps_values = []
        for r in kb_results:
            if r.get("throughput"):
                adapters.append(r.get("adapter_name", "Unknown"))
                qps_values.append(r["throughput"].get("qps", 0))
        if adapters:
            fig = go.Figure(data=[go.Bar(x=adapters, y=qps_values, marker_color='#2ecc71', text=qps_values, textposition='outside')])
            fig.update_layout(
                title='ååå¯¹æ¯” (QPS)',
                xaxis_title='çŸ¥è¯†åº“',
                yaxis_title='QPS',
                height=500,
                margin=dict(t=100, b=80, l=80, r=80)
            )
            html.append(f'<div class="chart-container"><h4>ååå¯¹æ¯”</h4><div id="{chart_id_prefix}-throughput"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-throughput", {fig.to_json()});</script>')

        # 3. æ£€ç´¢è´¨é‡å¯¹æ¯”å›¾
        adapters = []
        p1_values = []
        mrr_values = []
        ndcg_values = []
        for r in kb_results:
            if r.get("quality"):
                adapters.append(r.get("adapter_name", "Unknown"))
                qual = r["quality"]
                p1_values.append(qual.get("precision@1", 0))
                mrr_values.append(qual.get("mrr", 0))
                ndcg_values.append(qual.get("ndcg@10", 0))
        if adapters:
            fig = go.Figure()
            fig.add_trace(go.Bar(name='Precision@1', x=adapters, y=p1_values, marker_color='#1abc9c'))
            fig.add_trace(go.Bar(name='MRR', x=adapters, y=mrr_values, marker_color='#f39c12'))
            fig.add_trace(go.Bar(name='NDCG@10', x=adapters, y=ndcg_values, marker_color='#9b59b6'))
            fig.update_layout(
                title='æ£€ç´¢è´¨é‡å¯¹æ¯”',
                barmode='group',
                xaxis_title='çŸ¥è¯†åº“',
                yaxis_title='å¾—åˆ†',
                height=380,
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            html.append(f'<div class="chart-container"><h4>æ£€ç´¢è´¨é‡å¯¹æ¯”</h4><div id="{chart_id_prefix}-quality"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-quality", {fig.to_json()});</script>')

        # 4. æˆæœ¬å¯¹æ¯”å›¾ï¼ˆ100 æ–‡æ¡£è§„æ¨¡ä¼°ç®—ï¼Œç»Ÿä¸€ä¸ºäººæ°‘å¸ä¾¿äºå¯¹æ¯”ï¼‰
        cost_names = []
        cost_values = []
        cost_map = {
            "OpenSearch": 700 * 7.2,
            "Aurora": 44 * 7.2,
            "Volcengine": 300,
            "Alibaba": 200,
        }
        for r in kb_results:
            name = r.get("adapter_name", "")
            for key, val in cost_map.items():
                if key in name:
                    cost_names.append(name)
                    cost_values.append(val)
                    break
        if cost_names:
            fig = go.Figure(data=[go.Bar(x=cost_names, y=cost_values, marker_color='#e67e22')])
            fig.update_layout(
                title='æˆæœ¬å¯¹æ¯”ï¼ˆ100 æ–‡æ¡£è§„æ¨¡ï¼Œæœˆåº¦ä¼°ç®—ï¼Œå•ä½ï¼šå…ƒï¼‰',
                xaxis_title='çŸ¥è¯†åº“',
                yaxis_title='æœˆåº¦æˆæœ¬ (å…ƒ)',
                height=380
            )
            html.append(f'<div class="chart-container"><h4>æˆæœ¬å¯¹æ¯”</h4><div id="{chart_id_prefix}-cost"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-cost", {fig.to_json()});</script>')

        return '\n'.join(html)

    def _generate_comprehensive_kb_html_comparison(self, kb_results: List[Dict]) -> str:
        """ç”ŸæˆçŸ¥è¯†åº“ç»¼åˆå¯¹æ¯”çš„HTMLç‰ˆæœ¬"""
        html = []

        if len(kb_results) < 2:
            return ""

        # ç»¼åˆè¯„åˆ†è¡¨
        html.append('<h3>ğŸ† ç»¼åˆè¯„åˆ†å¯¹æ¯”</h3>')
        html.append('<table>')
        html.append('<tr><th>çŸ¥è¯†åº“</th><th>æ€§èƒ½å¾—åˆ†</th><th>è´¨é‡å¾—åˆ†</th><th>æˆæœ¬å¾—åˆ†</th><th>æ˜“ç”¨æ€§</th><th>ç»¼åˆè¯„åˆ†</th><th>æ¨èåœºæ™¯</th></tr>')

        for r in kb_results:
            adapter_name = r.get("adapter_name", "")
            lat = r.get("latency", {})
            tp = r.get("throughput", {})
            qual = r.get("quality", {})

            p50 = lat.get("p50_ms", 999999)
            qps = tp.get("qps", 0)
            mrr = qual.get("mrr", 0)
            p1 = qual.get("precision@1", 0)

            perf_score = min(5, max(1, int(5 - (p50 / 500))))
            qual_score = min(5, max(1, int((mrr + p1) * 2.5)))

            if "OpenSearch" in adapter_name:
                cost_score, ease_score, scenario = 2, 5, "æ€§èƒ½ä¼˜å…ˆ"
            elif "Aurora" in adapter_name:
                cost_score, ease_score, scenario = 5, 3, "æˆæœ¬ä¼˜å…ˆ"
            elif "Alibaba" in adapter_name:
                cost_score, ease_score, scenario = 4, 4, "è´¨é‡ä¼˜å…ˆ"
            elif "Volcengine" in adapter_name:
                cost_score, ease_score, scenario = 4, 3, "å›½å†…åº”ç”¨"
            else:
                cost_score, ease_score, scenario = 3, 3, "é€šç”¨"

            overall = int((perf_score + qual_score + cost_score + ease_score) / 4)

            perf_stars = "â­" * perf_score
            qual_stars = "â­" * qual_score
            cost_stars = "â­" * cost_score
            ease_stars = "â­" * ease_score
            overall_stars = "â­" * overall

            html.append(f'<tr><td><strong>{adapter_name}</strong></td><td>{perf_stars}</td><td>{qual_stars}</td><td>{cost_stars}</td><td>{ease_stars}</td><td>{overall_stars}</td><td>{scenario}</td></tr>')

        html.append('</table>')

        # è´¨é‡åˆ†æ
        html.append('<h3>ğŸ¯ æ£€ç´¢è´¨é‡æ·±åº¦åˆ†æ</h3>')

        sorted_by_mrr = sorted(kb_results, key=lambda r: r.get("quality", {}).get("mrr", 0), reverse=True)
        html.append('<ol>')
        for i, r in enumerate(sorted_by_mrr, 1):
            adapter_name = r.get("adapter_name", "Unknown")
            mrr = r.get("quality", {}).get("mrr", 0)
            p1 = r.get("quality", {}).get("precision@1", 0)

            medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1] if i <= 3 else ""
            html.append(f'<li>{medal} <strong>{adapter_name}</strong> - MRR: {mrr:.3f}, P@1: {p1:.3f}</li>')

        html.append('</ol>')

        # æ¶æ„å¯¹æ¯”å·²åœ¨å‰æ–‡ã€ŒğŸ—ï¸ æ¶æ„å¯¹æ¯”ã€ç« èŠ‚å•ç‹¬å±•ç¤ºï¼Œæ­¤å¤„ä¸å†é‡å¤

        return '\n'.join(html)

    def _generate_aws_bedrock_html_comparison(self, aws_results: List[Dict]) -> str:
        """ç”ŸæˆAWS Bedrockå¯¹æ¯”çš„HTMLç‰ˆæœ¬"""
        html = []
        opensearch_result = next((r for r in aws_results if "OpenSearch" in r.get("adapter_name", "")), None)
        aurora_result = next((r for r in aws_results if "Aurora" in r.get("adapter_name", "")), None)

        if not (opensearch_result and aurora_result):
            return ""

        os_lat = opensearch_result.get("latency", {})
        au_lat = aurora_result.get("latency", {})
        os_tp = opensearch_result.get("throughput", {})
        au_tp = aurora_result.get("throughput", {})

        html.append('<p>AWS Bedrock Knowledge Baseæ”¯æŒå¤šç§å‘é‡å­˜å‚¨åç«¯ï¼Œæœ¬æ¬¡æµ‹è¯•å¯¹æ¯”äº†ä¸¤ç§ä¸»æµæ–¹æ¡ˆï¼š</p>')

        html.append('<h3>æ€§èƒ½æŒ‡æ ‡è¯¦ç»†å¯¹æ¯”</h3>')
        html.append('<table>')
        html.append('<tr><th>æŒ‡æ ‡</th><th>OpenSearch Serverless</th><th>Aurora PostgreSQL Serverless</th><th>å·®å¼‚</th><th>èµ¢å®¶</th></tr>')

        # P50
        p50_diff = ((au_lat.get('p50_ms', 0) - os_lat.get('p50_ms', 0)) / os_lat.get('p50_ms', 1)) * 100
        p50_winner = "âœ… Aurora" if p50_diff < 0 else "âœ… OpenSearch"
        html.append(f'<tr><td><strong>P50 å»¶è¿Ÿ</strong></td><td>{os_lat.get("p50_ms", 0):.2f}ms</td><td>{au_lat.get("p50_ms", 0):.2f}ms</td><td>{p50_diff:+.1f}%</td><td>{p50_winner}</td></tr>')

        # P95
        p95_diff = ((au_lat.get('p95_ms', 0) - os_lat.get('p95_ms', 0)) / os_lat.get('p95_ms', 1)) * 100
        p95_winner = "âœ… Aurora" if p95_diff < 0 else "âœ… OpenSearch"
        html.append(f'<tr><td><strong>P95 å»¶è¿Ÿ</strong></td><td>{os_lat.get("p95_ms", 0):.2f}ms</td><td>{au_lat.get("p95_ms", 0):.2f}ms</td><td>{p95_diff:+.1f}%</td><td>{p95_winner}</td></tr>')

        # QPS
        qps_diff = ((au_tp.get('qps', 0) - os_tp.get('qps', 0)) / os_tp.get('qps', 1)) * 100
        qps_winner = "â‰ˆ ç›¸å½“" if abs(qps_diff) < 5 else ("âœ… Aurora" if qps_diff > 0 else "âœ… OpenSearch")
        html.append(f'<tr><td><strong>QPS</strong></td><td>{os_tp.get("qps", 0):.2f}</td><td>{au_tp.get("qps", 0):.2f}</td><td>{qps_diff:+.1f}%</td><td>{qps_winner}</td></tr>')

        html.append('</table>')

        html.append('<h3>å…³é”®å‘ç°</h3>')
        html.append('<ol>')
        html.append(f'<li><strong>ä¸­ä½æ•°æ€§èƒ½ (P50)</strong>: {"Aurora PostgreSQL Serverless è¡¨ç°ç•¥å¥½" if p50_diff < 0 else "OpenSearch Serverless è¡¨ç°ç•¥å¥½"}ï¼Œå·®å¼‚ {abs(p50_diff):.1f}%</li>')
        html.append(f'<li><strong>å°¾éƒ¨å»¶è¿Ÿ (P95/P99)</strong>: {"Aurora PostgreSQL Serverless æ›´ç¨³å®š" if p95_diff < 0 else "OpenSearch Serverless æ›´ç¨³å®š"}ï¼ŒP95å·®å¼‚ {abs(p95_diff):.1f}%</li>')
        html.append(f'<li><strong>ååé‡</strong>: ä¸¤è€…åŸºæœ¬ç›¸å½“ ({abs(qps_diff):.1f}% å·®å¼‚)</li>')
        html.append('<li><strong>æˆæœ¬</strong>: Aurora PostgreSQL Serverless æœ‰å‹å€’æ€§ä¼˜åŠ¿ï¼ˆè¯¦è§æˆæœ¬å¯¹æ¯”ç« èŠ‚ï¼‰</li>')
        html.append('</ol>')

        return '\n'.join(html)

    def _generate_cost_html_comparison(self, kb_results: List[Dict]) -> str:
        """ç”Ÿæˆæˆæœ¬å¯¹æ¯”çš„HTMLç‰ˆæœ¬"""
        html = []

        html.append('<h3>ğŸ“‰ æœˆåº¦æˆæœ¬ä¼°ç®—ï¼ˆ100æ–‡æ¡£è§„æ¨¡ï¼‰</h3>')
        html.append('<table>')
        html.append('<tr><th>æœåŠ¡</th><th>æ•°æ®é‡</th><th>æœˆåº¦æˆæœ¬</th><th>æˆæœ¬æ„æˆ</th></tr>')

        opensearch_result = next((r for r in kb_results if "OpenSearch" in r.get("adapter_name", "")), None)
        aurora_result = next((r for r in kb_results if "Aurora" in r.get("adapter_name", "")), None)

        if opensearch_result:
            html.append('<tr><td><strong>AWS Bedrock (OpenSearch)</strong></td><td>0.1GB</td><td>~$700/æœˆ</td><td>4 OCU Ã— $0.24 Ã— 730h</td></tr>')
        if aurora_result:
            html.append('<tr><td><strong>AWS Bedrock (Aurora PG)</strong></td><td>0.1GB</td><td>~$44/æœˆ</td><td>0.5 ACU Ã— $0.12 Ã— 730h</td></tr>')
        if any("Volcengine" in r.get("adapter_name", "") for r in kb_results):
            html.append('<tr><td><strong>ç«å±±å¼•æ“ VikingDB</strong></td><td>0.1GB</td><td>~Â¥300/æœˆ</td><td>å®ä¾‹è´¹ + å­˜å‚¨è´¹</td></tr>')
        if any("Alibaba" in r.get("adapter_name", "") for r in kb_results):
            html.append('<tr><td><strong>é˜¿é‡Œäº‘ç™¾ç‚¼</strong></td><td>0.1GB</td><td>~Â¥200/æœˆ</td><td>æŒ‰è°ƒç”¨æ¬¡æ•°è®¡è´¹</td></tr>')

        html.append('</table>')

        if opensearch_result and aurora_result:
            html.append('<h3>ğŸ’¡ æˆæœ¬èŠ‚çœåˆ†æ</h3>')
            html.append('<p>é€‰æ‹© <strong>Aurora PostgreSQL Serverless</strong> ç›¸æ¯” <strong>OpenSearch Serverless</strong>:</p>')
            html.append('<ul>')
            html.append('<li><strong>æœˆåº¦èŠ‚çœ</strong>: $656/æœˆ</li>')
            html.append('<li><strong>èŠ‚çœæ¯”ä¾‹</strong>: 93.7%</li>')
            html.append('<li><strong>å¹´åº¦èŠ‚çœ</strong>: $7,872/å¹´</li>')
            html.append('</ul>')

        html.append('<h3>ğŸ¯ é€‰å‹å»ºè®®</h3>')
        html.append('<h4>é»˜è®¤æ¨è: <strong>Aurora PostgreSQL Serverless v2</strong> â­</h4>')
        html.append('<p><strong>é€‚ç”¨åœºæ™¯</strong>:</p>')
        html.append('<ul>')
        html.append('<li>âœ… æˆæœ¬æ•æ„Ÿå‹é¡¹ç›®</li>')
        html.append('<li>âœ… éœ€è¦å®Œæ•´SQLèƒ½åŠ›</li>')
        html.append('<li>âœ… è¦æ±‚å¼ºä¸€è‡´æ€§</li>')
        html.append('<li>âœ… å·²æœ‰RDSåŸºç¡€è®¾æ–½</li>')
        html.append('<li>âœ… ä½åˆ°ä¸­ç­‰æŸ¥è¯¢é‡ï¼ˆ&lt; 1000 QPSï¼‰</li>')
        html.append('</ul>')

        return '\n'.join(html)
    
    # ============== è®°å¿†ç³»ç»Ÿä¸“ç”¨æ–¹æ³• ==============
    
    def _run_mode_label(self, run_mode: str) -> str:
        """è¿è¡Œæ¨¡å¼æ˜¾ç¤ºæ–‡æ¡ˆï¼šmock -> Mockï¼›real -> çœŸå®äº‘ï¼›å…¶ä»–(å¦‚ simple_store) -> æœ¬åœ°"""
        if run_mode == "mock":
            return "Mock æ¨¡å¼ï¼ˆæœ¬åœ°æ¨¡æ‹Ÿï¼‰"
        if run_mode == "real":
            return "çœŸå®äº‘ç¯å¢ƒ"
        return "æœ¬åœ°"

    def _append_memory_run_mode_table(self, lines: List[str], memory_results: List[Dict]) -> None:
        """åœ¨æŠ¥å‘Šä¸­è¿½åŠ è®°å¿†ç³»ç»Ÿè¿è¡Œæ¨¡å¼è¡¨ï¼ˆMock / çœŸå®äº‘ï¼‰"""
        lines.append("| è®°å¿†ç³»ç»Ÿ | è¿è¡Œæ¨¡å¼ |")
        lines.append("|----------|----------|")
        for r in memory_results:
            name = r.get("adapter_name", "-")
            run_mode = r.get("details", {}).get("run_mode", "unknown")
            lines.append(f"| {name} | {self._run_mode_label(run_mode)} |")
        lines.append("")

    def _generate_memory_intro(self, memory_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿä»‹ç»"""
        lines = []
        
        intro_map = {
            "AWSBedrockMemory": "**AWS Bedrock Memory** æ˜¯ Amazon Bedrock AgentCore æä¾›çš„æ‰˜ç®¡è®°å¿†æœåŠ¡ï¼Œæ”¯æŒçŸ­æœŸè®°å¿†(Events)å’Œé•¿æœŸè®°å¿†(Insights)ã€‚",
            "VolcengineAgentKitMemory": "**ç«å±±å¼•æ“ AgentKit Memory** æ˜¯å­—èŠ‚è·³åŠ¨ç«å±±å¼•æ“æä¾›çš„ Agent è®°å¿†ç®¡ç†æœåŠ¡ï¼Œæ”¯æŒå¯¹è¯è®°å¿†å’Œé•¿æœŸçŸ¥è¯†ç§¯ç´¯ã€‚",
            "AlibabaBailianMemory": "**é˜¿é‡Œäº‘ç™¾ç‚¼é•¿æœŸè®°å¿†** æ˜¯é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°æä¾›çš„è®°å¿†èŠ‚ç‚¹æœåŠ¡ï¼Œæ”¯æŒè®°å¿†çš„åˆ›å»ºã€æŸ¥è¯¢å’Œç®¡ç†ã€‚",
            "Mem0LocalAdapter": "**Mem0 (æœ¬åœ°)** æ˜¯å¼€æºçš„è®°å¿†ç®¡ç†æ¡†æ¶ï¼Œæ”¯æŒå¤šç§å‘é‡å­˜å‚¨åç«¯ï¼Œå¯ä½œä¸ºäº‘æœåŠ¡çš„å¯¹æ¯”åŸºå‡†ã€‚"
        }
        
        for r in memory_results:
            name = r.get("adapter_name", "Unknown")
            if name in intro_map:
                lines.append(f"- {intro_map[name]}")
        
        return lines
    
    def _generate_memory_architecture_comparison(self, memory_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæ¶æ„å¯¹æ¯”"""
        lines = []
        lines.append("| è®°å¿†ç³»ç»Ÿ | å­˜å‚¨æ–¹å¼ | è®°å¿†ç±»å‹ | ç´¢å¼•æ–¹å¼ | ç‰¹ç‚¹ |")
        lines.append("|----------|----------|----------|----------|------|")
        
        arch_map = {
            "AWSBedrockMemory": ("æ‰˜ç®¡å‘é‡å­˜å‚¨", "Events + Insights", "å‘é‡ç´¢å¼•", "è‡ªåŠ¨æå–é•¿æœŸè®°å¿†"),
            "VolcengineAgentKitMemory": ("ç«å±±å¼•æ“å­˜å‚¨", "å¯¹è¯è®°å¿† + é•¿æœŸè®°å¿†", "å‘é‡æ£€ç´¢", "Agent å·¥ä½œæµé›†æˆ"),
            "AlibabaBailianMemory": ("ç™¾ç‚¼å¹³å°å­˜å‚¨", "è®°å¿†èŠ‚ç‚¹", "å›¾è°± + å‘é‡", "æ”¯æŒè®°å¿†å…³è”"),
            "Mem0LocalAdapter": ("æœ¬åœ°å‘é‡åº“", "ç»Ÿä¸€è®°å¿†", "Embeddingæ£€ç´¢", "å¼€æºå¯å®šåˆ¶")
        }
        
        for r in memory_results:
            name = r.get("adapter_name", "Unknown")
            if name in arch_map:
                storage, mem_type, index, feature = arch_map[name]
                lines.append(f"| {name} | {storage} | {mem_type} | {index} | {feature} |")
        
        return lines
    
    def _generate_memory_test_methodology(self, data: ReportData) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæµ‹è¯•æ–¹æ³•è¯´æ˜"""
        lines = []
        memory_count = data.summary.get("memory_count", 100)
        user_count = data.summary.get("user_count", 10)
        query_count = data.summary.get("query_count", 5)

        lines.append("### æµ‹è¯•æ•°æ®")
        lines.append("")
        lines.append(f"- **è®°å¿†æ¡ç›®æ•°**: {memory_count} æ¡")
        lines.append(f"- **æ¨¡æ‹Ÿç”¨æˆ·æ•°**: {user_count} ä¸ª")
        lines.append(f"- **è®°å¿†ç±»å‹**: ç”¨æˆ·åå¥½ã€å¯¹è¯è®°å½•ã€å­¦ä¹ è¿›åº¦ç­‰")
        lines.append(f"- **æµ‹è¯•æŸ¥è¯¢æ•°**: {query_count} ä¸ªæŸ¥è¯¢è¯­å¥")
        lines.append("")

        lines.append("### æµ‹è¯•æµç¨‹")
        lines.append("")
        lines.append("1. **åˆå§‹åŒ–é˜¶æ®µ**")
        lines.append(f"   - åˆ›å»º {user_count} ä¸ªæ¨¡æ‹Ÿç”¨æˆ·è´¦å·")
        lines.append(f"   - ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆéšæœºçš„è®°å¿†æ•°æ®")
        lines.append("")
        lines.append("2. **è®°å¿†å†™å…¥æµ‹è¯•**")
        lines.append(f"   - æ‰¹é‡æ·»åŠ  {memory_count} æ¡æµ‹è¯•è®°å¿†")
        lines.append(f"   - è®°å½•æ¯æ¬¡å†™å…¥æ“ä½œçš„å“åº”æ—¶é—´")
        lines.append(f"   - è®¡ç®—å†™å…¥æˆåŠŸç‡")
        lines.append("")
        lines.append("3. **è®°å¿†æœç´¢æµ‹è¯•**")
        lines.append(f"   - æ‰§è¡Œ {query_count} ä¸ªä¸åŒçš„æŸ¥è¯¢è¯­å¥")
        lines.append(f"   - æ¯ä¸ªæŸ¥è¯¢é’ˆå¯¹ç‰¹å®šç”¨æˆ·è¿›è¡Œ")
        lines.append(f"   - è®°å½•æ¯æ¬¡æœç´¢çš„å“åº”æ—¶é—´å’Œè¿”å›ç»“æœæ•°")
        lines.append(f"   - è®¡ç®—æœç´¢æˆåŠŸç‡")
        lines.append("")
        lines.append("4. **æ€§èƒ½æŒ‡æ ‡æ”¶é›†**")
        lines.append(f"   - æ€»è¯·æ±‚æ•°: {memory_count} (å†™å…¥) + {query_count} (æœç´¢) = {memory_count + query_count} æ¬¡")
        lines.append(f"   - ç»Ÿè®¡æ‰€æœ‰æ“ä½œçš„å»¶è¿Ÿåˆ†å¸ƒ (P50/P95/P99)")
        lines.append(f"   - è®¡ç®—ååé‡ (QPS = æ€»è¯·æ±‚æ•° / æ€»è€—æ—¶)")
        lines.append("")

        lines.append("### è¯„ä¼°ç»´åº¦")
        lines.append("")
        lines.append("- **å»¶è¿Ÿ (Latency)**")
        lines.append("  - P50: 50%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹ï¼ˆä¸­ä½æ•°ï¼‰")
        lines.append("  - P95: 95%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹")
        lines.append("  - P99: 99%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹")
        lines.append("  - å¹³å‡å€¼: æ‰€æœ‰è¯·æ±‚çš„å¹³å‡å“åº”æ—¶é—´")
        lines.append("")
        lines.append("- **åå (Throughput)**")
        lines.append("  - QPS: æ¯ç§’å®Œæˆçš„æŸ¥è¯¢æ•° (Queries Per Second)")
        lines.append(f"  - æ€»è¯·æ±‚æ•°: åŒ…å«å†™å…¥å’Œæœç´¢çš„æ‰€æœ‰æ“ä½œ")
        lines.append("")
        lines.append("- **å¯é æ€§ (Reliability)**")
        lines.append("  - æˆåŠŸç‡: æˆåŠŸå®Œæˆçš„è¯·æ±‚æ•° / æ€»è¯·æ±‚æ•°")
        lines.append("  - å¤±è´¥åŸå› : APIè¶…æ—¶ã€é™æµã€è®¤è¯å¤±è´¥ç­‰")
        lines.append("")
        lines.append("- **æˆæœ¬ (Cost)**")
        lines.append("  - åŸºäºäº‘æœåŠ¡å•†çš„è®¡è´¹æ¨¡å¼ä¼°ç®—æœˆåº¦æˆæœ¬")
        lines.append("  - è€ƒè™‘å› ç´ : APIè°ƒç”¨æ¬¡æ•°ã€å­˜å‚¨å®¹é‡ã€æ•°æ®ä¼ è¾“ç­‰")

        return lines
    
    def _generate_memory_cost_table(self, memory_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæˆæœ¬å¯¹æ¯”è¡¨"""
        lines = []
        lines.append("| è®°å¿†ç³»ç»Ÿ | æœˆåº¦æˆæœ¬ä¼°ç®— | è®¡è´¹æ–¹å¼ | å¤‡æ³¨ |")
        lines.append("|----------|--------------|----------|------|")
        
        cost_map = {
            "AWSBedrockMemory": ("$50-100/æœˆ", "æŒ‰è®°å¿†å­˜å‚¨å’ŒæŸ¥è¯¢è®¡è´¹", "æ”¯æŒé•¿æœŸè®°å¿†è‡ªåŠ¨æå–"),
            "VolcengineAgentKitMemory": ("Â¥200-400/æœˆ", "æŒ‰Agentè°ƒç”¨æ¬¡æ•°", "åŒ…å«åœ¨Agentè´¹ç”¨ä¸­"),
            "AlibabaBailianMemory": ("Â¥150-300/æœˆ", "æŒ‰è®°å¿†èŠ‚ç‚¹æ•°", "æ”¯æŒè®°å¿†å…³è”æŸ¥è¯¢"),
            "Mem0LocalAdapter": ("è‡ªæ‰˜ç®¡æˆæœ¬", "æœåŠ¡å™¨ + å­˜å‚¨", "å¼€æºå…è´¹ï¼Œéœ€è‡ªè¡Œç»´æŠ¤")
        }
        
        for r in memory_results:
            name = r.get("adapter_name", "Unknown")
            if name in cost_map:
                cost, billing, note = cost_map[name]
                lines.append(f"| {name} | {cost} | {billing} | {note} |")
        
        lines.append("")
        lines.append("*æ³¨ï¼šæˆæœ¬ä¼°ç®—åŸºäº 100 æ¡è®°å¿†ã€10 ä¸ªç”¨æˆ·çš„æµ‹è¯•è§„æ¨¡ï¼Œå®é™…æˆæœ¬å› ä½¿ç”¨é‡è€Œå¼‚ã€‚*")
        
        return lines
    
    def _generate_comprehensive_memory_comparison(self, memory_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿç»¼åˆå¯¹æ¯”"""
        lines = []
        
        if len(memory_results) < 2:
            return lines
        
        lines.append("")
        lines.append("### ğŸ† ç»¼åˆè¯„åˆ†å¯¹æ¯”")
        lines.append("")
        lines.append("| è®°å¿†ç³»ç»Ÿ | æ€§èƒ½å¾—åˆ† | æˆæœ¬å¾—åˆ† | æ˜“ç”¨æ€§ | ç»¼åˆè¯„åˆ† | æ¨èåœºæ™¯ |")
        lines.append("|----------|----------|----------|--------|----------|----------|")
        
        for r in memory_results:
            adapter_name = r.get("adapter_name", "")
            lat = r.get("latency", {})
            tp = r.get("throughput", {})
            
            p50 = lat.get("p50_ms", 999999)
            qps = tp.get("qps", 0)
            
            # æ€§èƒ½è¯„åˆ†ï¼šåŸºäºå»¶è¿Ÿ
            perf_score = min(5, max(1, int(5 - (p50 / 200))))
            
            # æˆæœ¬å’Œæ˜“ç”¨æ€§è¯„åˆ†ï¼ˆåŸºäºç»éªŒå€¼ï¼‰
            if "Bedrock" in adapter_name:
                cost_score, ease_score, scenario = 3, 5, "AWS ç”Ÿæ€"
            elif "Volcengine" in adapter_name:
                cost_score, ease_score, scenario = 4, 4, "å›½å†…ä¸­æ–‡åœºæ™¯"
            elif "Alibaba" in adapter_name:
                cost_score, ease_score, scenario = 4, 4, "é˜¿é‡Œäº‘ç”Ÿæ€"
            elif "Mem0" in adapter_name:
                cost_score, ease_score, scenario = 5, 3, "è‡ªæ‰˜ç®¡/å¼€æº"
            else:
                cost_score, ease_score, scenario = 3, 3, "é€šç”¨"
            
            overall = int((perf_score + cost_score + ease_score) / 3)
            
            lines.append(f"| {adapter_name} | {perf_score}/5 | {cost_score}/5 | {ease_score}/5 | {overall}/5 | {scenario} |")
        
        return lines
    
    def _generate_memory_selection_recommendation(self, memory_results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿé€‰å‹å»ºè®®"""
        lines = []
        
        lines.append("### ğŸ¯ AWS Bedrock Memory")
        lines.append("")
        lines.append("**é€‚åˆåœºæ™¯**:")
        lines.append("- ä½¿ç”¨ AWS äº‘æœåŠ¡çš„ä¼ä¸š")
        lines.append("- éœ€è¦è‡ªåŠ¨æå–é•¿æœŸè®°å¿† (Insights)")
        lines.append("- å¯¹æ‰˜ç®¡æœåŠ¡æœ‰å¼ºéœ€æ±‚")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**: æ‰˜ç®¡æœåŠ¡ã€ä¸ Bedrock Agent é›†æˆã€è‡ªåŠ¨è®°å¿†ç®¡ç†")
        lines.append("")
        lines.append("**åŠ£åŠ¿**: æˆæœ¬ç›¸å¯¹è¾ƒé«˜ã€éœ€è¦ AWS è´¦å·")
        lines.append("")
        
        lines.append("### ğŸ¯ ç«å±±å¼•æ“ AgentKit Memory")
        lines.append("")
        lines.append("**é€‚åˆåœºæ™¯**:")
        lines.append("- å›½å†…ä¼ä¸šï¼Œä¸­æ–‡åº”ç”¨åœºæ™¯")
        lines.append("- éœ€è¦ä¸ç«å±±å¼•æ“ Agent å·¥ä½œæµé›†æˆ")
        lines.append("- å¯¹ä¸­æ–‡è®°å¿†æ£€ç´¢æœ‰è¾ƒé«˜è¦æ±‚")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**: å›½å†…æœåŠ¡ã€ä¸­æ–‡ä¼˜åŒ–ã€Agent å·¥ä½œæµé›†æˆ")
        lines.append("")
        lines.append("**åŠ£åŠ¿**: éœ€è¦ç«å±±å¼•æ“è´¦å·ã€æ–‡æ¡£ç›¸å¯¹è¾ƒå°‘")
        lines.append("")
        
        lines.append("### ğŸ¯ é˜¿é‡Œäº‘ç™¾ç‚¼é•¿æœŸè®°å¿†")
        lines.append("")
        lines.append("**é€‚åˆåœºæ™¯**:")
        lines.append("- ä½¿ç”¨é˜¿é‡Œäº‘ç”Ÿæ€çš„ä¼ä¸š")
        lines.append("- éœ€è¦è®°å¿†å…³è”å’Œå›¾è°±èƒ½åŠ›")
        lines.append("- å›½å†…ä¸­æ–‡åœºæ™¯")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**: é˜¿é‡Œäº‘ç”Ÿæ€ã€æ”¯æŒè®°å¿†å…³è”ã€ä¸­æ–‡ä¼˜åŒ–")
        lines.append("")
        lines.append("**åŠ£åŠ¿**: éœ€è¦é˜¿é‡Œäº‘è´¦å·ã€API é™æµè¾ƒä¸¥æ ¼")
        lines.append("")
        
        lines.append("### ğŸ¯ Mem0 (æœ¬åœ°å¼€æº)")
        lines.append("")
        lines.append("**é€‚åˆåœºæ™¯**:")
        lines.append("- éœ€è¦å®Œå…¨æ§åˆ¶æ•°æ®çš„ä¼ä¸š")
        lines.append("- å¼€å‘æµ‹è¯•ç¯å¢ƒ")
        lines.append("- å¯¹æˆæœ¬æ•æ„Ÿçš„é¡¹ç›®")
        lines.append("")
        lines.append("**ä¼˜åŠ¿**: å¼€æºå…è´¹ã€æ•°æ®è‡ªä¸»ã€é«˜åº¦å¯å®šåˆ¶")
        lines.append("")
        lines.append("**åŠ£åŠ¿**: éœ€è¦è‡ªè¡Œç»´æŠ¤ã€ç¼ºå°‘æ‰˜ç®¡æœåŠ¡çš„ä¾¿åˆ©æ€§")
        
        return lines

    # ============== è®°å¿†ç³»ç»Ÿ HTML ä¸“ç”¨æ–¹æ³• ==============
    
    def _generate_memory_intro_html(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿä»‹ç»çš„HTML"""
        intro_map = {
            "Mem0LocalAdapter": ("Mem0 (æœ¬åœ°)", "å¼€æºçš„è®°å¿†ç®¡ç†æ¡†æ¶ï¼Œæ”¯æŒå¤šç§å‘é‡å­˜å‚¨åç«¯ï¼Œå¯ä½œä¸ºäº‘æœåŠ¡çš„å¯¹æ¯”åŸºå‡†ã€‚"),
            "AWSBedrockMemory": ("AWS Bedrock Memory", "Amazon Bedrock AgentCore æä¾›çš„æ‰˜ç®¡è®°å¿†æœåŠ¡ï¼Œæ”¯æŒçŸ­æœŸè®°å¿†(Events)å’Œé•¿æœŸè®°å¿†(Insights)ã€‚"),
            "VolcengineAgentKitMemory": ("ç«å±±å¼•æ“ AgentKit Memory", "å­—èŠ‚è·³åŠ¨ç«å±±å¼•æ“æä¾›çš„ Agent è®°å¿†ç®¡ç†æœåŠ¡ï¼Œæ”¯æŒå¯¹è¯è®°å¿†å’Œé•¿æœŸçŸ¥è¯†ç§¯ç´¯ã€‚"),
            "AlibabaBailianMemory": ("é˜¿é‡Œäº‘ç™¾ç‚¼é•¿æœŸè®°å¿†", "é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°æä¾›çš„è®°å¿†èŠ‚ç‚¹æœåŠ¡ï¼Œæ”¯æŒè®°å¿†çš„åˆ›å»ºã€æŸ¥è¯¢å’Œç®¡ç†ã€‚")
        }
        
        parts = ['<p>æœ¬æŠ¥å‘Šå¯¹æ¯”ä»¥ä¸‹ <strong>4 ä¸ªè®°å¿†ç³»ç»Ÿ</strong>ï¼š</p><ul>']
        for r in memory_results:
            name = r.get("adapter_name", "")
            if name in intro_map:
                title, desc = intro_map[name]
                parts.append(f'<li><strong>{title}</strong>ï¼š{desc}</li>')
        parts.append('</ul>')
        return '\n'.join(parts)
    
    def _generate_memory_architecture_html_comparison(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæ¶æ„å¯¹æ¯”çš„HTML"""
        html = []
        html.append('<table>')
        html.append('<tr><th>è®°å¿†ç³»ç»Ÿ</th><th>å­˜å‚¨æ–¹å¼</th><th>è®°å¿†ç±»å‹</th><th>ç´¢å¼•æ–¹å¼</th><th>ç‰¹ç‚¹</th></tr>')
        
        arch_map = {
            "Mem0LocalAdapter": ("æœ¬åœ°å‘é‡åº“", "ç»Ÿä¸€è®°å¿†", "Embeddingæ£€ç´¢", "å¼€æºå¯å®šåˆ¶"),
            "AWSBedrockMemory": ("æ‰˜ç®¡å‘é‡å­˜å‚¨", "Events + Insights", "å‘é‡ç´¢å¼•", "è‡ªåŠ¨æå–é•¿æœŸè®°å¿†"),
            "VolcengineAgentKitMemory": ("ç«å±±å¼•æ“å­˜å‚¨", "å¯¹è¯è®°å¿† + é•¿æœŸè®°å¿†", "å‘é‡æ£€ç´¢", "Agent å·¥ä½œæµé›†æˆ"),
            "AlibabaBailianMemory": ("ç™¾ç‚¼å¹³å°å­˜å‚¨", "è®°å¿†èŠ‚ç‚¹", "å›¾è°± + å‘é‡", "æ”¯æŒè®°å¿†å…³è”")
        }
        
        for r in memory_results:
            name = r.get("adapter_name", "")
            if name in arch_map:
                storage, mem_type, index, feature = arch_map[name]
                html.append(f'<tr><td><strong>{name}</strong></td><td>{storage}</td><td>{mem_type}</td><td>{index}</td><td>{feature}</td></tr>')
        
        html.append('</table>')
        return '\n'.join(html)
    
    def _generate_memory_test_methodology_html(self, data: ReportData) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæµ‹è¯•æ–¹æ³•çš„HTML"""
        memory_count = data.summary.get("memory_count", 100)
        user_count = data.summary.get("user_count", 10)
        query_count = data.summary.get("query_count", 5)

        return f"""<h3>æµ‹è¯•æ•°æ®</h3>
<ul>
<li><strong>è®°å¿†æ¡ç›®æ•°</strong>ï¼š{memory_count} æ¡</li>
<li><strong>æ¨¡æ‹Ÿç”¨æˆ·æ•°</strong>ï¼š{user_count} ä¸ª</li>
<li><strong>è®°å¿†ç±»å‹</strong>ï¼šç”¨æˆ·åå¥½ã€å¯¹è¯è®°å½•ã€å­¦ä¹ è¿›åº¦ç­‰</li>
<li><strong>æµ‹è¯•æŸ¥è¯¢æ•°</strong>ï¼š{query_count} ä¸ªæŸ¥è¯¢è¯­å¥</li>
</ul>

<h3>æµ‹è¯•æµç¨‹</h3>
<ol>
<li><strong>åˆå§‹åŒ–é˜¶æ®µ</strong>
  <ul>
    <li>åˆ›å»º {user_count} ä¸ªæ¨¡æ‹Ÿç”¨æˆ·è´¦å·</li>
    <li>ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆéšæœºçš„è®°å¿†æ•°æ®</li>
  </ul>
</li>
<li><strong>è®°å¿†å†™å…¥æµ‹è¯•</strong>
  <ul>
    <li>æ‰¹é‡æ·»åŠ  {memory_count} æ¡æµ‹è¯•è®°å¿†</li>
    <li>è®°å½•æ¯æ¬¡å†™å…¥æ“ä½œçš„å“åº”æ—¶é—´</li>
    <li>è®¡ç®—å†™å…¥æˆåŠŸç‡</li>
  </ul>
</li>
<li><strong>è®°å¿†æœç´¢æµ‹è¯•</strong>
  <ul>
    <li>æ‰§è¡Œ {query_count} ä¸ªä¸åŒçš„æŸ¥è¯¢è¯­å¥</li>
    <li>æ¯ä¸ªæŸ¥è¯¢é’ˆå¯¹ç‰¹å®šç”¨æˆ·è¿›è¡Œ</li>
    <li>è®°å½•æ¯æ¬¡æœç´¢çš„å“åº”æ—¶é—´å’Œè¿”å›ç»“æœæ•°</li>
    <li>è®¡ç®—æœç´¢æˆåŠŸç‡</li>
  </ul>
</li>
<li><strong>æ€§èƒ½æŒ‡æ ‡æ”¶é›†</strong>
  <ul>
    <li>æ€»è¯·æ±‚æ•°: {memory_count} (å†™å…¥) + {query_count} (æœç´¢) = {memory_count + query_count} æ¬¡</li>
    <li>ç»Ÿè®¡æ‰€æœ‰æ“ä½œçš„å»¶è¿Ÿåˆ†å¸ƒ (P50/P95/P99)</li>
    <li>è®¡ç®—ååé‡ (QPS = æ€»è¯·æ±‚æ•° / æ€»è€—æ—¶)</li>
  </ul>
</li>
</ol>

<h3>è¯„ä¼°ç»´åº¦</h3>
<ul>
<li><strong>å»¶è¿Ÿ (Latency)</strong>
  <ul>
    <li>P50: 50%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹ï¼ˆä¸­ä½æ•°ï¼‰</li>
    <li>P95: 95%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹</li>
    <li>P99: 99%çš„è¯·æ±‚å“åº”æ—¶é—´åœ¨æ­¤å€¼ä»¥ä¸‹</li>
    <li>å¹³å‡å€¼: æ‰€æœ‰è¯·æ±‚çš„å¹³å‡å“åº”æ—¶é—´</li>
  </ul>
</li>
<li><strong>åå (Throughput)</strong>
  <ul>
    <li>QPS: æ¯ç§’å®Œæˆçš„æŸ¥è¯¢æ•° (Queries Per Second)</li>
    <li>æ€»è¯·æ±‚æ•°: åŒ…å«å†™å…¥å’Œæœç´¢çš„æ‰€æœ‰æ“ä½œ</li>
  </ul>
</li>
<li><strong>å¯é æ€§ (Reliability)</strong>
  <ul>
    <li>æˆåŠŸç‡: æˆåŠŸå®Œæˆçš„è¯·æ±‚æ•° / æ€»è¯·æ±‚æ•°</li>
    <li>å¤±è´¥åŸå› : APIè¶…æ—¶ã€é™æµã€è®¤è¯å¤±è´¥ç­‰</li>
  </ul>
</li>
<li><strong>æˆæœ¬ (Cost)</strong>
  <ul>
    <li>åŸºäºäº‘æœåŠ¡å•†çš„è®¡è´¹æ¨¡å¼ä¼°ç®—æœˆåº¦æˆæœ¬</li>
    <li>è€ƒè™‘å› ç´ : APIè°ƒç”¨æ¬¡æ•°ã€å­˜å‚¨å®¹é‡ã€æ•°æ®ä¼ è¾“ç­‰</li>
  </ul>
</li>
</ul>"""
    
    def _generate_memory_performance_charts(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        html = []
        chart_id_prefix = "memory-chart"

        # 1. æ—¶å»¶å¯¹æ¯”å›¾
        adapters = []
        p50_values = []
        p95_values = []
        p99_values = []
        for r in memory_results:
            if r.get("latency"):
                adapters.append(r.get("adapter_name", "Unknown"))
                lat = r["latency"]
                p50_values.append(lat.get("p50_ms", 0))
                p95_values.append(lat.get("p95_ms", 0))
                p99_values.append(lat.get("p99_ms", 0))
        
        if adapters:
            fig = go.Figure()
            fig.add_trace(go.Bar(name='P50å»¶è¿Ÿ', x=adapters, y=p50_values, marker_color='#3498db'))
            fig.add_trace(go.Bar(name='P95å»¶è¿Ÿ', x=adapters, y=p95_values, marker_color='#e74c3c'))
            fig.add_trace(go.Bar(name='P99å»¶è¿Ÿ', x=adapters, y=p99_values, marker_color='#9b59b6'))
            fig.update_layout(
                title='æ—¶å»¶å¯¹æ¯” (ms)',
                barmode='group',
                xaxis_title='è®°å¿†ç³»ç»Ÿ',
                yaxis_title='å»¶è¿Ÿ (ms)',
                height=400,
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            html.append(f'<div class="chart-container"><h4>æ—¶å»¶å¯¹æ¯”</h4><div id="{chart_id_prefix}-latency"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-latency", {fig.to_json()});</script>')

        # 2. ååå¯¹æ¯”å›¾ (QPS)
        adapters = []
        qps_values = []
        for r in memory_results:
            if r.get("throughput"):
                adapters.append(r.get("adapter_name", "Unknown"))
                qps_values.append(r["throughput"].get("qps", 0))
        
        if adapters:
            fig = go.Figure(data=[go.Bar(x=adapters, y=qps_values, marker_color='#2ecc71', text=qps_values, textposition='outside')])
            fig.update_layout(
                title='ååå¯¹æ¯” (QPS)',
                xaxis_title='è®°å¿†ç³»ç»Ÿ',
                yaxis_title='QPS',
                height=500,
                margin=dict(t=100, b=80, l=80, r=80)
            )
            html.append(f'<div class="chart-container"><h4>ååå¯¹æ¯”</h4><div id="{chart_id_prefix}-throughput"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-throughput", {fig.to_json()});</script>')

        # 3. æˆåŠŸç‡å¯¹æ¯”å›¾
        adapters = []
        success_rates = []
        for r in memory_results:
            if r.get("throughput"):
                adapters.append(r.get("adapter_name", "Unknown"))
                error_rate = r["throughput"].get("error_rate", 0)
                success_rates.append(100 - error_rate)
        
        if adapters:
            fig = go.Figure(data=[go.Bar(x=adapters, y=success_rates, marker_color='#1abc9c', text=[f"{s:.1f}%" for s in success_rates], textposition='outside')])
            fig.update_layout(
                title='æˆåŠŸç‡å¯¹æ¯”',
                xaxis_title='è®°å¿†ç³»ç»Ÿ',
                yaxis_title='æˆåŠŸç‡ (%)',
                height=500,
                margin=dict(t=100, b=80, l=80, r=80),
                yaxis=dict(range=[0, 105])
            )
            html.append(f'<div class="chart-container"><h4>æˆåŠŸç‡å¯¹æ¯”</h4><div id="{chart_id_prefix}-success"></div></div>')
            html.append(f'<script>Plotly.newPlot("{chart_id_prefix}-success", {fig.to_json()});</script>')

        return '\n'.join(html)
    
    def _generate_memory_run_mode_table_html(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿè¿è¡Œæ¨¡å¼è¡¨ HTML"""
        html = []
        html.append('<table><tr><th>è®°å¿†ç³»ç»Ÿ</th><th>è¿è¡Œæ¨¡å¼</th></tr>')
        for r in memory_results:
            name = r.get("adapter_name", "-")
            run_mode = r.get("details", {}).get("run_mode", "unknown")
            label = self._run_mode_label(run_mode)
            if run_mode == "mock":
                badge = '<span class="badge badge-info">Mock æ¨¡å¼ï¼ˆæœ¬åœ°æ¨¡æ‹Ÿï¼‰</span>'
            elif run_mode == "real":
                badge = '<span class="badge badge-success">çœŸå®äº‘ç¯å¢ƒ</span>'
            else:
                badge = '<span class="badge badge-info">æœ¬åœ°</span>'
            html.append(f'<tr><td><strong>{name}</strong></td><td>{badge}</td></tr>')
        html.append('</table>')
        return '\n'.join(html)

    def _generate_memory_results_table_html(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿç»“æœè¡¨æ ¼HTML"""
        html = []
        html.append('<table>')
        html.append('<tr><th>è®°å¿†ç³»ç»Ÿ</th><th>è¿è¡Œæ¨¡å¼</th><th>P50å»¶è¿Ÿ</th><th>P95å»¶è¿Ÿ</th><th>P99å»¶è¿Ÿ</th><th>QPS</th><th>æˆåŠŸç‡</th></tr>')
        
        for r in memory_results:
            adapter = r.get("adapter_name", "-")
            run_mode = r.get("details", {}).get("run_mode", "unknown")
            if run_mode == "mock":
                mode_badge = '<span class="badge badge-info">Mock</span>'
            elif run_mode == "real":
                mode_badge = '<span class="badge badge-success">çœŸå®äº‘</span>'
            else:
                mode_badge = '<span class="badge badge-info">æœ¬åœ°</span>'
            lat = r.get("latency", {})
            tp = r.get("throughput", {})
            
            p50 = f"{lat.get('p50_ms', 0):.2f}ms" if lat else "-"
            p95 = f"{lat.get('p95_ms', 0):.2f}ms" if lat else "-"
            p99 = f"{lat.get('p99_ms', 0):.2f}ms" if lat else "-"
            qps = f"{tp.get('qps', 0):.1f}" if tp else "-"
            success = f"{100 - tp.get('error_rate', 0):.1f}%" if tp else "-"
            
            html.append(f'<tr><td><strong>{adapter}</strong></td><td>{mode_badge}</td><td>{p50}</td><td>{p95}</td><td>{p99}</td><td>{qps}</td><td>{success}</td></tr>')
        
        html.append('</table>')
        return '\n'.join(html)
    
    def _generate_comprehensive_memory_html_comparison(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿç»¼åˆå¯¹æ¯”çš„HTMLç‰ˆæœ¬"""
        html = []
        
        if len(memory_results) < 2:
            return ""
        
        html.append('<h3>ğŸ† ç»¼åˆè¯„åˆ†å¯¹æ¯”</h3>')
        html.append('<table>')
        html.append('<tr><th>è®°å¿†ç³»ç»Ÿ</th><th>æ€§èƒ½å¾—åˆ†</th><th>æˆæœ¬å¾—åˆ†</th><th>æ˜“ç”¨æ€§</th><th>ç»¼åˆè¯„åˆ†</th><th>æ¨èåœºæ™¯</th></tr>')
        
        for r in memory_results:
            adapter_name = r.get("adapter_name", "")
            lat = r.get("latency", {})
            
            p50 = lat.get("p50_ms", 999999)
            
            # æ€§èƒ½è¯„åˆ†
            perf_score = min(5, max(1, int(5 - (p50 / 200))))
            
            # æˆæœ¬å’Œæ˜“ç”¨æ€§è¯„åˆ†
            if "Bedrock" in adapter_name:
                cost_score, ease_score, scenario = 3, 5, "AWS ç”Ÿæ€"
            elif "Volcengine" in adapter_name:
                cost_score, ease_score, scenario = 4, 4, "å›½å†…ä¸­æ–‡åœºæ™¯"
            elif "Alibaba" in adapter_name:
                cost_score, ease_score, scenario = 4, 4, "é˜¿é‡Œäº‘ç”Ÿæ€"
            elif "Mem0" in adapter_name:
                cost_score, ease_score, scenario = 5, 3, "è‡ªæ‰˜ç®¡/å¼€æº"
            else:
                cost_score, ease_score, scenario = 3, 3, "é€šç”¨"
            
            overall = int((perf_score + cost_score + ease_score) / 3)
            
            html.append(f'<tr><td><strong>{adapter_name}</strong></td><td>{perf_score}/5</td><td>{cost_score}/5</td><td>{ease_score}/5</td><td>{overall}/5</td><td>{scenario}</td></tr>')
        
        html.append('</table>')
        return '\n'.join(html)
    
    def _generate_memory_selection_recommendation_html(self, memory_results: List[Dict]) -> str:
        """ç”Ÿæˆè®°å¿†ç³»ç»Ÿé€‰å‹å»ºè®®çš„HTML"""
        return """<p>æ ¹æ®å»¶è¿Ÿã€ååå’Œæˆæœ¬å¯¹æ¯”ï¼Œå»ºè®®æŒ‰åœºæ™¯é€‰å‹ï¼š</p>
<table>
<tr><th>åœºæ™¯</th><th>æ¨èç³»ç»Ÿ</th><th>è¯´æ˜</th></tr>
<tr><td><strong>AWS ç”Ÿæ€ç”¨æˆ·</strong></td><td>AWS Bedrock Memory</td><td>æ‰˜ç®¡æœåŠ¡ï¼Œè‡ªåŠ¨æå–é•¿æœŸè®°å¿†(Insights)ï¼Œä¸Bedrock Agentæ·±åº¦é›†æˆã€‚</td></tr>
<tr><td><strong>å›½å†…ä¸­æ–‡åœºæ™¯</strong></td><td>ç«å±±å¼•æ“ AgentKit Memory</td><td>å›½å†…æœåŠ¡ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼ŒAgentå·¥ä½œæµé›†æˆï¼Œæ€§èƒ½ä¼˜ç§€ã€‚</td></tr>
<tr><td><strong>é˜¿é‡Œäº‘ç”Ÿæ€</strong></td><td>é˜¿é‡Œäº‘ç™¾ç‚¼é•¿æœŸè®°å¿†</td><td>æ”¯æŒè®°å¿†å…³è”å’Œå›¾è°±èƒ½åŠ›ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼Œé€‚åˆé˜¿é‡Œäº‘ç”¨æˆ·ã€‚</td></tr>
<tr><td><strong>å¼€å‘æµ‹è¯•/æˆæœ¬æ•æ„Ÿ</strong></td><td>Mem0 (æœ¬åœ°)</td><td>å¼€æºå…è´¹ï¼Œæ•°æ®è‡ªä¸»ï¼Œé«˜åº¦å¯å®šåˆ¶ï¼Œéœ€è‡ªè¡Œç»´æŠ¤ã€‚</td></tr>
</table>

<p><strong>ç®€è¦ç»“è®º</strong>ï¼š</p>
<ul>
<li>é€‰ <strong>AWS Bedrock Memory</strong>ï¼šAWS ç”Ÿæ€ã€éœ€è¦æ‰˜ç®¡æœåŠ¡ã€è‡ªåŠ¨è®°å¿†ç®¡ç†ã€‚</li>
<li>é€‰ <strong>ç«å±±å¼•æ“ AgentKit</strong>ï¼šå›½å†…ä¸šåŠ¡ã€ä¸­æ–‡åœºæ™¯ã€æ€§èƒ½è¦æ±‚é«˜ã€‚</li>
<li>é€‰ <strong>é˜¿é‡Œäº‘ç™¾ç‚¼</strong>ï¼šé˜¿é‡Œäº‘ç”Ÿæ€ã€éœ€è¦è®°å¿†å…³è”èƒ½åŠ›ã€‚</li>
<li>é€‰ <strong>Mem0 æœ¬åœ°</strong>ï¼šå¼€å‘æµ‹è¯•ã€æ•°æ®è‡ªä¸»ã€æˆæœ¬æ•æ„Ÿã€‚</li>
</ul>"""

    def _sync_to_web_reports(self, generated_files: Dict[str, str]) -> None:
        """åŒæ­¥æŠ¥å‘Šåˆ° web/reports ç›®å½•ï¼ˆç”¨äº Railway éƒ¨ç½²ï¼‰

        Args:
            generated_files: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        try:
            import shutil

            # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ web/reports è·¯å¾„
            current_file = Path(__file__)
            project_root = current_file.parent.parent.parent
            web_reports_dir = project_root / "web" / "reports"

            # å¦‚æœ web/reports ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
            if not web_reports_dir.exists():
                web_reports_dir.mkdir(parents=True, exist_ok=True)
                logger.debug(f"åˆ›å»º web/reports ç›®å½•: {web_reports_dir}")

            # å¤åˆ¶æ¯ä¸ªç”Ÿæˆçš„æ–‡ä»¶åˆ° web/reports
            synced_count = 0
            for file_type, file_path in generated_files.items():
                source_file = Path(file_path)
                if source_file.exists():
                    dest_file = web_reports_dir / source_file.name
                    shutil.copy2(source_file, dest_file)
                    logger.debug(f"åŒæ­¥æŠ¥å‘Šåˆ° web: {source_file.name}")
                    synced_count += 1

            if synced_count > 0:
                logger.info(f"âœ“ å·²åŒæ­¥ {synced_count} ä¸ªæŠ¥å‘Šæ–‡ä»¶åˆ° web/reports ç›®å½•")
                logger.info(f"  æç¤º: æäº¤ä»£ç å Railway å°†æ˜¾ç¤ºæœ€æ–°æŠ¥å‘Š")

        except Exception as e:
            logger.warning(f"åŒæ­¥æŠ¥å‘Šåˆ° web/reports å¤±è´¥ (ä¸å½±å“æŠ¥å‘Šç”Ÿæˆ): {e}")

