# 需求分析文档

## 1. 项目背景

本项目旨在对多个云端Agent知识库和记忆系统进行性能测试和对比评估，帮助进行技术选型决策。

## 2. 测试目标系统

### 2.1 知识库系统（5个）

| 序号 | 云服务商 | 服务名称 | 备注 |
|------|----------|----------|------|
| 1 | AWS | Bedrock Knowledge Base | Amazon托管RAG服务 |
| 2 | Google Cloud | Dialogflow Knowledge Base | 对话式AI知识库 |
| 3 | 字节跳动 | 火山引擎 Viking 知识库 | 向量数据库+RAG |
| 4 | 阿里云 | 百炼平台知识库 | 通义千问生态 |
| 5 | 华为云 | CSS (Cloud Search Service) | 企业搜索服务 |

### 2.2 记忆系统（5个）

| 序号 | 云服务商 | 服务名称 | 备注 |
|------|----------|----------|------|
| 1 | AWS | Bedrock Memory | Agent记忆管理 |
| 2 | Google Cloud | Vertex AI Agent Engine Memory Bank | Agent记忆存储 |
| 3 | 字节跳动 | 火山引擎 AgentKit Memory | Agent记忆组件 |
| 4 | 阿里云 | 百炼平台长期记忆 | 通义千问长期记忆 |
| 5 | 本地部署 | mem0 (开源) | 自托管记忆系统 |

## 3. 测试场景

### 3.1 知识库测试场景

#### 3.1.1 文档管理场景
- **文档上传**：测试不同大小、格式文档的上传性能
- **文档索引**：测试向量化和索引构建时间
- **文档更新**：测试已有文档的更新性能
- **文档删除**：测试文档删除及索引更新性能

#### 3.1.2 检索查询场景
- **单次查询**：测试单个查询的延迟
- **批量查询**：测试批量查询的吞吐量
- **并发查询**：测试不同并发级别下的性能表现

### 3.2 记忆系统测试场景

#### 3.2.1 长期记忆场景（主要）
- **记忆写入**：跨会话记忆的存储性能
- **记忆检索**：从大量历史记忆中召回相关记忆
- **记忆更新**：已有记忆的修改和合并
- **记忆老化**：测试记忆衰减和清理机制

## 4. 测试数据规模

### 4.1 知识库数据规模（三档对比）

| 规模 | 文档数量 | 总大小 | 单文档平均大小 |
|------|----------|--------|----------------|
| 小规模 | 100 | ~10MB | ~100KB |
| 中规模 | 1,000 | ~100MB | ~100KB |
| 大规模 | 10,000 | ~1GB | ~100KB |

### 4.2 记忆系统数据规模

| 指标 | 数值 |
|------|------|
| 记忆条数 | 1,000+ 条 |
| 模拟用户数 | 10-100 |
| 跨会话天数 | 模拟30天+ |

## 5. 性能指标

### 5.1 延迟指标
- P50 延迟（中位数）
- P95 延迟
- P99 延迟
- 首字节时间（TTFB）
- 平均响应时间

### 5.2 吞吐量指标
- QPS（每秒查询数）
- 并发处理能力
- 最大稳定吞吐量

### 5.3 质量指标
- 检索准确率（Precision）
- 召回率（Recall）
- F1 分数
- MRR（Mean Reciprocal Rank）
- NDCG（Normalized Discounted Cumulative Gain）

### 5.4 成本指标
- 单次查询成本
- 存储成本（每GB/月）
- 索引成本
- 总体TCO对比

## 6. 并发测试规模

采用阶梯式压力测试：

| 阶段 | 并发数 | 目的 |
|------|--------|------|
| 阶段1 | 1-10 | 基准性能，单用户体验 |
| 阶段2 | 10-50 | 小团队使用场景 |
| 阶段3 | 50-100 | 中等负载场景 |
| 阶段4 | 100-500 | 高负载场景 |
| 阶段5 | 500-1000 | 极限压力测试 |

## 7. Benchmark 选择

### 7.1 知识库评测基准

| Benchmark | 用途 | 说明 |
|-----------|------|------|
| BEIR | 检索质量评估 | 包含多个检索任务数据集 |
| MTEB | 嵌入模型评估 | 多任务文本嵌入基准 |
| MS MARCO | 段落检索 | 大规模阅读理解数据集 |

### 7.2 记忆系统评测基准

| Benchmark | 用途 | 说明 |
|-----------|------|------|
| MemBench | 记忆能力评估 | 长期记忆召回测试 |
| 自定义场景 | 业务相关性 | 模拟真实对话场景 |

## 8. 输出物

### 8.1 测试报告
- Markdown 格式源文件
- HTML 可视化报告（含图表）

### 8.2 报告内容
- 各系统性能数据表格
- 性能对比图表
- 成本分析
- 选型建议

## 9. 技术约束

### 9.1 开发语言
- Python 3.10+

### 9.2 配置管理
- 敏感信息（API Key、密码）存放在独立配置文件
- 配置文件加入 .gitignore，不提交到版本库
- 提供配置模板文件供参考

### 9.3 代码复用
- 抽象统一的适配器接口
- 复用认证、错误处理、重试等公共模块
- 生成可复用的 skill

## 10. 待确认事项

- [ ] 各云服务账号申请和配额
- [ ] 测试数据集的具体内容和来源
- [ ] 测试环境（本地/云服务器）
- [ ] 测试时间窗口和频率
